{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Uplift Modeling for Churn Prediction\n",
        "\n",
        "Short notebook: same workflow as the full notebook, using **utils** for all logic.\n",
        "Run cells in order. Data paths: `train/` and `test/` under project root.\n",
        "\n",
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebe7f8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup may take 30–60s: utils imports sentence_transformers, causalml, lightgbm, xgboost.\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "try:\n",
        "    from causalml.metrics import qini_auc_score\n",
        "except Exception:\n",
        "    qini_auc_score = None\n",
        "\n",
        "from utils import (\n",
        "    approx_auuc, assign_segments, build_claims_labels, build_feature_matrix, build_recency_tenure,\n",
        "    count_events_before_signup, DOW_NAMES, embed_wellco_brief, EMBED_MODEL_NAME, feat_distribution_summary,\n",
        "    feature_diagnostics, FOCUS_ICD_CODES, load_wellco_brief, missingness_and_member_coverage,\n",
        "    missingness_mechanism_analysis, plot_balance, plot_correlation_diagnostics, plot_feature_histograms,\n",
        "    print_focus_icd_stats, print_table_overview, RANDOM_STATE, ref_date_from_tables,\n",
        "    run_relevance_filter_sanity_check, SIMILARITY_THRESHOLD, time_bin, uplift_at_k, uplift_by_groups,\n",
        "    uplift_curve, _build_model,\n",
        ")\n",
        "\n",
        "pd.set_option('display.max_columns', 200)\n",
        "BASE_DIR = Path('.').resolve()\n",
        "TRAIN_DIR = BASE_DIR / 'train'\n",
        "TEST_DIR = BASE_DIR / 'test'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bea74bdf",
      "metadata": {},
      "source": [
        "## 2. Load data\n",
        "Train/test CSVs; train events restricted to observation window (July 1–15, 2025).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ff02e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training data\n",
        "churn_labels = pd.read_csv(TRAIN_DIR / \"churn_labels.csv\", parse_dates=[\"signup_date\"])\n",
        "app_usage = pd.read_csv(TRAIN_DIR / \"app_usage.csv\", parse_dates=[\"timestamp\"])\n",
        "web_visits = pd.read_csv(TRAIN_DIR / \"web_visits.csv\", parse_dates=[\"timestamp\"])\n",
        "claims = pd.read_csv(TRAIN_DIR / \"claims.csv\", parse_dates=[\"diagnosis_date\"])\n",
        "\n",
        "# Test data\n",
        "test_members = pd.read_csv(TEST_DIR / \"test_members.csv\", parse_dates=[\"signup_date\"])\n",
        "test_app_usage = pd.read_csv(TEST_DIR / \"test_app_usage.csv\", parse_dates=[\"timestamp\"])\n",
        "test_web_visits = pd.read_csv(TEST_DIR / \"test_web_visits.csv\", parse_dates=[\"timestamp\"])\n",
        "test_claims = pd.read_csv(TEST_DIR / \"test_claims.csv\", parse_dates=[\"diagnosis_date\"])\n",
        "\n",
        "# Observation window: July 1 - July 15, 2025 (pre-outreach). Outreach = July 15; churn measured after.\n",
        "# Restrict train event data only; test data is not filtered (outreach has not occurred for test).\n",
        "OBS_START = pd.Timestamp(\"2025-07-01\")\n",
        "OBS_END   = pd.Timestamp(\"2025-07-15\")  # exclusive: keep events strictly before outreach\n",
        "\n",
        "web_visits = web_visits[(web_visits[\"timestamp\"] >= OBS_START) & (web_visits[\"timestamp\"] < OBS_END)]\n",
        "app_usage  = app_usage[(app_usage[\"timestamp\"] >= OBS_START) & (app_usage[\"timestamp\"] < OBS_END)]\n",
        "claims     = claims[(claims[\"diagnosis_date\"] >= OBS_START) & (claims[\"diagnosis_date\"] < OBS_END)]\n",
        "\n",
        "# Quick sanity check\n",
        "for name, df in {\n",
        "    \"churn_labels\": churn_labels,\n",
        "    \"app_usage\": app_usage,\n",
        "    \"web_visits\": web_visits,\n",
        "    \"claims\": claims,\n",
        "    \"test_members\": test_members,\n",
        "    \"test_app_usage\": test_app_usage,\n",
        "    \"test_web_visits\": test_web_visits,\n",
        "    \"test_claims\": test_claims,\n",
        "}.items():\n",
        "    print(f\"{name}: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cebf3193",
      "metadata": {},
      "source": [
        "## **3. EDA**\n",
        "\n",
        "Exploratory data analysis: table structure, missingness, treatment balance, leakage checks, and uplift by engagement/claims/recency.\n",
        "\n",
        "---\n",
        "\n",
        "### **3.1 Raw data overview**\n",
        "Summarize structure, dtypes, and sample rows for all 8 tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b3f7be7",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_tables = {\n",
        "    \"churn_labels\": churn_labels,\n",
        "    \"app_usage\": app_usage,\n",
        "    \"web_visits\": web_visits,\n",
        "    \"claims\": claims,\n",
        "    \"test_members\": test_members,\n",
        "    \"test_app_usage\": test_app_usage,\n",
        "    \"test_web_visits\": test_web_visits,\n",
        "    \"test_claims\": test_claims,\n",
        "}\n",
        "\n",
        "for name, df in all_tables.items():\n",
        "    print_table_overview(name, df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca42dbf3",
      "metadata": {},
      "source": [
        "### 3.2 Column-specific checks\n",
        "event_type, url, title, icd_code for feature-engineering decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887b8601",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.1 Column-specific checks\n",
        "# Purpose: Check special columns (event_type, url, title, icd_code) for feature engineering decisions.\n",
        "# What we test: value_counts for event_type, url, title, icd_code.\n",
        "# What we do with this info:\n",
        "#   - If event_type is constant -> drop it.\n",
        "#   - URL/title variety -> potential content-categorization features.\n",
        "#   - ICD distribution -> guides focus-ICD flag design.\n",
        "# ----------\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"  Column-specific checks\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\napp_usage event_type value_counts:\")\n",
        "print(app_usage[\"event_type\"].value_counts().to_string())\n",
        "print(f\"  -> {'CONSTANT — can drop' if app_usage['event_type'].nunique() == 1 else 'MULTIPLE VALUES — keep'}\")\n",
        "\n",
        "# url and title in web_visits: content variety\n",
        "print(f\"\\nweb_visits url: {web_visits['url'].nunique()} unique values\")\n",
        "print(\"  Top-5 URLs:\")\n",
        "print(web_visits[\"url\"].value_counts().head(5).to_string())\n",
        "print(f\"\\nweb_visits title: {web_visits['title'].nunique()} unique values\")\n",
        "print(\"  Top-5 titles:\")\n",
        "print(web_visits[\"title\"].value_counts().head(5).to_string())\n",
        "\n",
        "# icd_code in claims\n",
        "print(f\"\\nclaims icd_code: {claims['icd_code'].nunique()} unique values\")\n",
        "print(\"  Top-10 ICD codes:\")\n",
        "print(claims[\"icd_code\"].value_counts().head(10).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bb9f4e8",
      "metadata": {},
      "source": [
        "### 3.3 Missing values and member coverage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faedfb71",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.2 Missing values and member coverage (utils: missingness_and_member_coverage)\n",
        "missingness_and_member_coverage(all_tables, churn_labels, web_visits, app_usage, claims, test_members, test_web_visits, test_app_usage, test_claims)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a9c7e4",
      "metadata": {},
      "source": [
        "### 3.4 Missingness mechanism (Chi-square)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca91d91",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.4 Missingness mechanism (utils: missingness_mechanism_analysis)\n",
        "missingness_mechanism_analysis(churn_labels, web_visits, app_usage, claims)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5102b06",
      "metadata": {},
      "source": [
        "**What it means:** Chi-square p-values and the bar chart show whether churn (or outreach) rate differs between members who have activity in a source vs those who do not. The cross-tab shows how many members are missing from each combination of sources.\n",
        "\n",
        "**What it says about further analysis:**  p-values are large (e.g. > 0.05), missingness is not strongly related to churn/outreach → zero-fill is enough."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2df7ae",
      "metadata": {},
      "source": [
        "### 3.5 Labels & treatment balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0356fa97",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.4 Labels and treatment balance\n",
        "churn_rate = churn_labels[\"churn\"].mean()\n",
        "outreach_rate = churn_labels[\"outreach\"].mean()\n",
        "\n",
        "summary_labels = churn_labels.groupby(\"outreach\")[\"churn\"].agg([\n",
        "    (\"members\", \"count\"),\n",
        "    (\"churn_rate\", \"mean\"),\n",
        "])\n",
        "\n",
        "print(f\"Overall churn rate: {churn_rate:.3f}\")\n",
        "print(f\"Outreach rate: {outreach_rate:.3f}\")\n",
        "print(\"\\nOutreach x Churn cross-tabulation:\")\n",
        "cross_tab = pd.crosstab(churn_labels[\"outreach\"], churn_labels[\"churn\"],\n",
        "                        margins=True, margins_name=\"Total\")\n",
        "print(cross_tab.to_string())\n",
        "print(\"\\nChurn rates by group:\")\n",
        "print(summary_labels.to_string())\n",
        "\n",
        "plot_balance(churn_labels, \"outreach\", \"Outreach vs. control counts\", \"Outreach\", \"Count\")\n",
        "plot_balance(churn_labels, \"churn\", \"Churn label counts\", \"Churn\", \"Count\")\n",
        "plot_balance(summary_labels.reset_index(), \"outreach\", \"Churn rate by outreach group\", \"Outreach\", \"Churn rate\", y=\"churn_rate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ddaa7d",
      "metadata": {},
      "source": [
        "### 3.6 Leakage & time-window validation (utils: `count_events_before_signup`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2494d3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "window_summary = pd.DataFrame([\n",
        "    {'table': 'web_visits', 'min': web_visits['timestamp'].min(), 'max': web_visits['timestamp'].max()},\n",
        "    {'table': 'app_usage', 'min': app_usage['timestamp'].min(), 'max': app_usage['timestamp'].max()},\n",
        "    {'table': 'claims', 'min': claims['diagnosis_date'].min(), 'max': claims['diagnosis_date'].max()},\n",
        "])\n",
        "leakage = pd.DataFrame([\n",
        "    {'table': 'web_visits', 'events_before_signup': count_events_before_signup(web_visits, 'timestamp', churn_labels)},\n",
        "    {'table': 'app_usage', 'events_before_signup': count_events_before_signup(app_usage, 'timestamp', churn_labels)},\n",
        "    {'table': 'claims', 'events_before_signup': count_events_before_signup(claims, 'diagnosis_date', churn_labels)},\n",
        "])\n",
        "display(window_summary)\n",
        "display(leakage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1670220",
      "metadata": {},
      "source": [
        "**What it means:** The first table shows min/max timestamps per event table (all within July 1–14, 2025). The second table shows zero events before signup for web, app, and claims — no leakage.\n",
        "\n",
        "**What it says about further analysis:** Observation window and signup logic are consistent. We can safely use these events for feature engineering. Next: temporal and engagement uplift (3.6, 3.7)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75eecc0d",
      "metadata": {},
      "source": [
        "### 3.7 Temporal features as uplift moderators\n",
        "\n",
        "Uplift = P(churn=1 | outreach=1, bin) − P(churn=1 | outreach=0, bin).\n",
        "\n",
        "Each bar shows uplift among members who had **at least one event** in that bin. The same member may appear in multiple bins.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34cc570e",
      "metadata": {},
      "outputs": [],
      "source": [
        "web_ev = web_visits[['member_id', 'timestamp']].copy(); web_ev['hour'] = web_ev['timestamp'].dt.hour; web_ev['dow'] = web_ev['timestamp'].dt.dayofweek\n",
        "app_ev = app_usage[['member_id', 'timestamp']].copy(); app_ev['hour'] = app_ev['timestamp'].dt.hour; app_ev['dow'] = app_ev['timestamp'].dt.dayofweek\n",
        "\n",
        "events = pd.concat([web_ev[['member_id', 'hour', 'dow']], app_ev[['member_id', 'hour', 'dow']]], ignore_index=True)\n",
        "events['time_of_day'] = events['hour'].apply(time_bin)\n",
        "events['dow_name'] = events['dow'].map(DOW_NAMES)\n",
        "events['is_weekend'] = events['dow'].isin([5, 6])\n",
        "labels = churn_labels[['member_id', 'churn', 'outreach']]\n",
        "print('Events:', len(events), 'rows,', events['member_id'].nunique(), 'members')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e4fcf9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by time of day\n",
        "uplift_by_groups(events, labels, \"time_of_day\", [\"Early Morning\", \"Morning\", \"Afternoon\", \"Evening\"], title=\"Uplift by time of day\", xlabel=\"Time of day\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2250876",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by day of week\n",
        "uplift_by_groups(events, labels, \"dow_name\", [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"], title=\"Uplift by day of week\", xlabel=\"Day of week\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e276ba4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by weekend vs weekday\n",
        "uplift_by_groups(events, labels, \"is_weekend\", [False, True], plot_labels=[\"Weekday\", \"Weekend\"], title=\"Uplift by weekend vs weekday\", xlabel=\"Day type\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968477fd",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by time of day and by weekday vs weekend is similar across bins (all slightly negative). Outreach reduces churn a bit regardless of when members are active.\n",
        "\n",
        "**What it says about further analysis:** Temporal features (time of day, day of week, weekend) do not strongly moderate uplift. Next: engagement and claims\n",
        "\n",
        "### 3.8 Engagement features as uplift moderators\n",
        "\n",
        "**(a)** Distribution sanity checks — log-scaled histograms and quantile summaries.  \n",
        "**(b)** Uplift by engagement quartile for each feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acac0fab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution sanity checks (engagement)\n",
        "\n",
        "web_per = web_visits.groupby(\"member_id\").size().rename(\"web_visits_count\").reset_index()\n",
        "app_per = app_usage.groupby(\"member_id\").size().rename(\"app_sessions_count\").reset_index()\n",
        "url_div = web_visits.groupby(\"member_id\")[\"url\"].nunique().rename(\"url_nunique\").reset_index()\n",
        "\n",
        "eng = churn_labels[[\"member_id\", \"churn\", \"outreach\"]].merge(\n",
        "    web_per, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    app_per, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    url_div, on=\"member_id\", how=\"left\"\n",
        ")\n",
        "for col in [\"web_visits_count\", \"app_sessions_count\", \"url_nunique\"]:\n",
        "    eng[col] = eng[col].fillna(0)\n",
        "\n",
        "feat_distribution_summary(eng, \"web_visits_count\")\n",
        "feat_distribution_summary(eng, \"app_sessions_count\")\n",
        "feat_distribution_summary(eng, \"url_nunique\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8c1032f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by web_visits_count quartile\n",
        "eng[\"web_q\"] = pd.qcut(eng[\"web_visits_count\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(eng, labels, \"web_q\", sorted(eng[\"web_q\"].dropna().unique()), title=\"Uplift by web visits quartile\", xlabel=\"Web visits (quartile)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a2c86e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by app_sessions_count quartile\n",
        "eng[\"app_q\"] = pd.qcut(eng[\"app_sessions_count\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(eng, labels, \"app_q\", sorted(eng[\"app_q\"].dropna().unique()), title=\"Uplift by app sessions quartile\", xlabel=\"App sessions (quartile)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5e7f9b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by URL diversity quartile\n",
        "eng[\"url_q\"] = pd.qcut(eng[\"url_nunique\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(eng, labels, \"url_q\", sorted(eng[\"url_q\"].dropna().unique()), title=\"Uplift by URL diversity quartile\", xlabel=\"Unique URLs (quartile)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d40f820",
      "metadata": {},
      "source": [
        "**What it means:** Engagement (event counts, sessions, URL diversity) shows uplift varying by quartile; some bins have near-zero or slightly positive uplift.\n",
        "\n",
        "**What it says about further analysis:** Engagement level can moderate uplift — useful as features for the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b105e7cb",
      "metadata": {},
      "source": [
        "### 3.9 Claims features as uplift moderators\n",
        "\n",
        "**(a)** Distribution sanity checks — log-scaled histograms, quantile summaries, focus-ICD prevalence.  \n",
        "**(b)** Uplift by claims strata: quartile bins for counts, binary for has-focus-ICD, and 0/1/2/3 for count of focus ICDs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639389f1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Distribution sanity checks (claims)\n",
        "cl = build_claims_labels(claims, churn_labels)\n",
        "feat_distribution_summary(cl, \"claims_count\", color=\"green\")\n",
        "feat_distribution_summary(cl, \"icd_nunique\", color=\"green\")\n",
        "print_focus_icd_stats(cl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b17437",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by claims_count quartile\n",
        "cl[\"claims_q\"] = pd.qcut(cl[\"claims_count\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(cl, labels, \"claims_q\", sorted(cl[\"claims_q\"].dropna().unique()), title=\"Uplift by claims count quartile\", xlabel=\"Claims count (quartile)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b10abfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by icd_nunique quartile\n",
        "cl[\"icd_q\"] = pd.qcut(cl[\"icd_nunique\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(cl, labels, \"icd_q\", sorted(cl[\"icd_q\"].dropna().unique()), title=\"Uplift by distinct ICD codes quartile\", xlabel=\"Distinct ICD codes (quartile)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10fe7621",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by has focus ICD (binary: No / Yes)\n",
        "uplift_by_groups(cl, labels, \"has_focus_icd\", [0, 1], plot_labels=[\"No focus ICD\", \"Has focus ICD\"], title=\"Uplift by has focus ICD\", xlabel=\"Focus ICD status\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36ff0019",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by count of focus ICDs (0, 1, 2, 3)\n",
        "uplift_by_groups(cl, labels, \"focus_icd_count\", [0, 1, 2, 3], plot_labels=[\"0 focus ICD\", \"1 focus ICD\", \"2 focus ICD\", \"3 focus ICD\"], title=\"Uplift by count of focus ICDs\", xlabel=\"Number of distinct focus ICD codes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4436ec",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by claims (count, focus ICD, quartiles) varies across groups; some segments show stronger or weaker outreach effects.\n",
        "\n",
        "**What it says about further analysis:** Claims-based features are useful for targeting. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af2059e8",
      "metadata": {},
      "source": [
        "### 3.10 Recency & tenure (utils: `build_recency_tenure`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99d096a",
      "metadata": {},
      "outputs": [],
      "source": [
        "recency_df, ref_date = build_recency_tenure(churn_labels, web_visits, app_usage, claims)\n",
        "rec = churn_labels[['member_id', 'churn', 'outreach']].merge(recency_df, left_on='member_id', right_index=True)\n",
        "print('Ref date:', ref_date)\n",
        "print(f\"Members: {len(rec)}\")\n",
        "print(rec[['days_since_last_web', 'days_since_last_app', 'days_since_last_activity', 'tenure_days']].describe().round(1).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc42a8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by days_since_last_web quartile\n",
        "feat = \"days_since_last_web\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "valid[\"quartile_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"quartile_bin\"].nunique() < 2:\n",
        "    valid[\"quartile_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "uplift_by_groups(valid, labels, \"quartile_bin\", sorted(valid[\"quartile_bin\"].dropna().unique()), title=\"Uplift by days since last web activity\", xlabel=\"Days-since-last-web bin\")\n",
        "print(f\"Excluded from plot (no web activity): {excluded} members (n too small for stable uplift).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23fe2ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by days_since_last_app quartile\n",
        "feat = \"days_since_last_app\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "valid[\"quartile_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"quartile_bin\"].nunique() < 2:\n",
        "    valid[\"quartile_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "uplift_by_groups(valid, labels, \"quartile_bin\", sorted(valid[\"quartile_bin\"].dropna().unique()), title=\"Uplift by days since last app activity\", xlabel=\"Days-since-last-app bin\")\n",
        "print(f\"Excluded from plot (no app activity): {excluded} members (n too small for stable uplift).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aabad8cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by days_since_last_claim quartile\n",
        "feat = \"days_since_last_claim\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "valid[\"quartile_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"quartile_bin\"].nunique() < 2:\n",
        "    valid[\"quartile_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "uplift_by_groups(valid, labels, \"quartile_bin\", sorted(valid[\"quartile_bin\"].dropna().unique()), title=\"Uplift by days since last claim\", xlabel=\"Days-since-last-claim bin\")\n",
        "print(f\"Excluded from plot (no claims): {excluded} members (n too small for stable uplift).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab843c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by days_since_last_activity quartile\n",
        "feat = \"days_since_last_activity\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "valid[\"quartile_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"quartile_bin\"].nunique() < 2:\n",
        "    valid[\"quartile_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "uplift_by_groups(valid, labels, \"quartile_bin\", sorted(valid[\"quartile_bin\"].dropna().unique()), title=\"Uplift by days since last activity (any source)\", xlabel=\"Days-since-last-activity bin\")\n",
        "print(f\"Excluded from plot (no activity at all): {excluded} members (n too small for stable uplift).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa915203",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uplift by tenure_days quartile\n",
        "feat = \"tenure_days\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "valid[\"quartile_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"quartile_bin\"].nunique() < 2:\n",
        "    valid[\"quartile_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "uplift_by_groups(valid, labels, \"quartile_bin\", sorted(valid[\"quartile_bin\"].dropna().unique()), title=\"Uplift by tenure (days since signup)\", xlabel=\"Tenure bin (days)\")\n",
        "print(f\"Excluded from plot (missing signup_date): {excluded} members (n too small for stable uplift).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f682eaf2",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by recency and tenure bins shows how outreach effect varies with how recently members were active and how long they have been members.\n",
        "\n",
        "**What it says about further analysis:** Recency and tenure are strong candidates for the uplift model. EDA is complete."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cc4d80f",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering\n",
        "Config; load WellCo brief and embedding model once; then build train/test feature matrices (utils).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284b8d55",
      "metadata": {},
      "outputs": [],
      "source": [
        "WELLCO_BRIEF_PATH = BASE_DIR / 'wellco_client_brief.txt'\n",
        "print(f\"Similarity threshold – {SIMILARITY_THRESHOLD}\")\n",
        "print(f\"Embedding model      – {EMBED_MODEL_NAME}\")\n",
        "print(f\"Focus ICD codes      – {FOCUS_ICD_CODES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8bae96",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── RUN ONCE: load embedding model & embed WellCo brief ────────────────────\n",
        "# This cell is intentionally isolated so it runs exactly once per session.\n",
        "# All downstream cells reuse `embed_model` and `wellco_embedding`.\n",
        "\n",
        "brief_text = load_wellco_brief()\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "wellco_embedding = embed_wellco_brief(brief_text, embed_model)  # shape (1, dim)\n",
        "\n",
        "print(f\"WellCo brief loaded     – {len(brief_text):,} characters\")\n",
        "print(f\"Embedding model loaded  – {EMBED_MODEL_NAME}\")\n",
        "print(f\"WellCo embedding shape  – {wellco_embedding.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e3296b",
      "metadata": {},
      "outputs": [],
      "source": [
        "ref_date_train = ref_date_from_tables(web_visits, app_usage, claims)\n",
        "ref_date_test  = ref_date_from_tables(test_web_visits, test_app_usage, test_claims)\n",
        "print('ref_date_train:', ref_date_train, '| ref_date_test:', ref_date_test)\n",
        "\n",
        "print('Building TRAIN feature matrix...')\n",
        "train_features = build_feature_matrix(churn_labels, web_visits, app_usage, claims, ref_date_train,\n",
        "    wellco_embedding=wellco_embedding, embed_model=embed_model, include_labels=True)\n",
        "    \n",
        "print('Building TEST feature matrix...')\n",
        "test_features = build_feature_matrix(test_members, test_web_visits, test_app_usage, test_claims, ref_date_test,\n",
        "    wellco_embedding=wellco_embedding, embed_model=embed_model, include_labels=False)\n",
        "\n",
        "# --- Quick summary ----------------------------------------------------------\n",
        "print(f\"\\nTrain features shape: {train_features.shape}\")\n",
        "print(f\"Test  features shape: {test_features.shape}\")\n",
        "print(f\"\\nTrain columns: {list(train_features.columns)}\")\n",
        "print(f\"Test  columns: {list(test_features.columns)}\")\n",
        "print(f\"\\nTrain head:\\n{train_features.head()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fce11826",
      "metadata": {},
      "source": [
        "### 4.1 Feature diagnostics (informational only)\n",
        "Inspect distributions and multicollinearity of the engineered features **on the training set**. This section is for review only — no features are automatically dropped or transformed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c67b68",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6a  Per-feature distribution diagnostics ──────────────────────────────\n",
        "# Feature columns only (exclude member_id and labels)\n",
        "FEATURE_COLS = [\n",
        "    \"wellco_web_visits_count\",\n",
        "    # TOGGLE: uncomment next line to include URL feature in diagnostics\n",
        "    # \"wellco_web_unique_urls\",\n",
        "    \"days_since_last_wellco_web\",\n",
        "    \"app_sessions_count\",\n",
        "    \"icd_distinct_count\",\n",
        "    \"has_focus_icd\",\n",
        "    \"days_since_last_claim\",\n",
        "    \"tenure_days\",\n",
        "]\n",
        "feature_diagnostics(train_features, FEATURE_COLS, title_suffix=\"(train)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e351efc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6b  Histograms ────────────────────────────────────────────────────────\n",
        "# Each plot: x = feature value, y = how many members have that value.\n",
        "FEATURE_XLABELS = {\n",
        "    \"wellco_web_visits_count\": \"Relevant web visits per member\",\n",
        "    \"wellco_web_unique_urls\": \"Unique URLs (WellCo-relevant visits)\",\n",
        "    \"days_since_last_wellco_web\": \"Days since last relevant web visit\",\n",
        "    \"app_sessions_count\": \"App sessions per member\",\n",
        "    \"icd_distinct_count\": \"Distinct ICD codes per member\",\n",
        "    \"has_focus_icd\": \"Has focus ICD (0 = no, 1 = yes)\",\n",
        "    \"days_since_last_claim\": \"Days since last claim\",\n",
        "    \"tenure_days\": \"Tenure (days since signup)\",\n",
        "}\n",
        "plot_feature_histograms(train_features, FEATURE_COLS, xlabels=FEATURE_XLABELS, suptitle=\"Feature distributions: how many members have each value (train set)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0d7e87d",
      "metadata": {},
      "source": [
        "**What we see in these distribution plots (train set):** Each histogram shows how many members have each value for one feature. **wellco_web_visits_count:** Strong right skew; most members in the 0–5 or 5–14 range, long tail up to 62 visits — a few heavy engagers. **wellco_web_unique_urls:** Almost identical shape to visit count (same data, one row per URL), so redundant; we drop it from the matrix. **days_since_last_wellco_web:** Right-skewed; many at 0–1 days, tail out to 13; ~2% missing (no relevant visit). **app_sessions_count:** More symmetric, roughly bell-shaped; median ~10, less skew than web/claims. **icd_distinct_count:** Multi-modal (several peaks at 4, 5, 6 codes). **has_focus_icd:** Almost all 1 (92%+); near-binary. **days_since_last_claim:** Right-skewed; peak at 1–2 days. **tenure_days:** Right-skewed; spread from 45 to 561 days. For tree-based uplift models we use these as-is; for linear models we'd log1p skewed counts and keep binary 0/1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fee2b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6c  Multicollinearity diagnostic ──────────────────────────────────────\n",
        "plot_correlation_diagnostics(train_features, FEATURE_COLS, threshold=0.8, title_suffix=\"(train set)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43869299",
      "metadata": {},
      "source": [
        "**What we see in this heatmap:** The plot above is the correlation matrix of the 8 feature columns (including `wellco_web_unique_urls`). The only pair with |r| ≥ 0.8 is **wellco_web_visits_count** and **wellco_web_unique_urls** — they are **perfectly correlated** (r = 1.0). That is because both were computed from the same WellCo-relevant rows: in that subset each visit is one row and one URL, so the two counts are identical. All other pairs in this matrix are moderate or weak (e.g. tenure vs. recency, app vs. web); no other near-perfect correlation appears. **Decision:** We drop `wellco_web_unique_urls` from the feature matrix for modeling (7 features) to avoid multicollinearity; the diagnostics above still show the 8-feature version so it is clear we tried the URL feature and why we dropped it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67924f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6d  Uplift by WellCo-relevant web features ───────────────────────────\n",
        "# Uses uplift_by_groups with labels; train_features has the three web features.\n",
        "web_uplift_df = train_features[[\"member_id\", \"wellco_web_visits_count\", \"wellco_web_unique_urls\", \"days_since_last_wellco_web\"]].copy()\n",
        "\n",
        "# 1. Uplift by wellco_web_visits_count (quartiles)\n",
        "web_uplift_df[\"quartile_bin\"] = pd.qcut(web_uplift_df[\"wellco_web_visits_count\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(web_uplift_df, labels, \"quartile_bin\", sorted(web_uplift_df[\"quartile_bin\"].dropna().unique()), title=\"Uplift by WellCo-relevant web visits (count)\", xlabel=\"wellco_web_visits_count (quartile)\")\n",
        "\n",
        "# 2. Uplift by wellco_web_unique_urls (quartiles)\n",
        "web_uplift_df[\"quartile_bin\"] = pd.qcut(web_uplift_df[\"wellco_web_unique_urls\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(web_uplift_df, labels, \"quartile_bin\", sorted(web_uplift_df[\"quartile_bin\"].dropna().unique()), title=\"Uplift by WellCo-relevant unique URLs\", xlabel=\"wellco_web_unique_urls (quartile)\")\n",
        "\n",
        "# 3. Uplift by days_since_last_wellco_web (quartiles); exclude members with no relevant visits\n",
        "valid_web = web_uplift_df.dropna(subset=[\"days_since_last_wellco_web\"]).copy()\n",
        "n_excluded_web = len(web_uplift_df) - len(valid_web)\n",
        "valid_web[\"quartile_bin\"] = pd.qcut(valid_web[\"days_since_last_wellco_web\"], q=4, duplicates=\"drop\")\n",
        "uplift_by_groups(valid_web, labels, \"quartile_bin\", sorted(valid_web[\"quartile_bin\"].dropna().unique()), title=\"Uplift by days since last WellCo-relevant web visit\", xlabel=\"days_since_last_wellco_web (quartile)\")\n",
        "print(f\"Excluded from plot (no relevant web visits): {n_excluded_web} members.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3089ec6",
      "metadata": {},
      "source": [
        "**What we see in these uplift plots:** Each bar chart bins members by quartiles of one WellCo-relevant web feature and shows the **uplift** (churn rate difference: control − treated) in that bin. **Plot 1 (wellco_web_visits_count):** Uplift is small and slightly negative across quartiles; more visits do not show a clearly stronger or weaker outreach effect here. **Plot 2 (wellco_web_unique_urls):** Mirrors the visit-count plot (same redundancy as in the correlation heatmap); we kept this plot to show we tried the URL feature. **Plot 3 (days_since_last_wellco_web):** Members with no relevant visit are excluded; across quartiles uplift is again modest. Overall, these filtered web features show some variation in uplift by segment but no single strong moderator; they remain useful as inputs to the uplift model rather than as standalone targeting rules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da930b1e",
      "metadata": {},
      "source": [
        "### 4.2 Embeding + relevance filter sanity test\n",
        "The 26 unique (title, description) pairs in the web data split into two groups based on the WellCo brief (nutrition, exercise, sleep, stress, diabetes, hypertension, cardiometabolic health). If the test passes, the threshold is separating relevant from non-relevant correctly on these unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4288812",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4.7 Relevance filter sanity test (logic in utils.run_relevance_filter_sanity_check)\n",
        "run_relevance_filter_sanity_check(wellco_embedding, embed_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80345081",
      "metadata": {},
      "source": [
        "## 5. Model Selection — Uplift CV\n",
        "Stratified K-fold CV; compare S/T/X-learner × LGBM/XGB with AUUC, Qini, uplift@k (utils: `_build_model`, metric helpers).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7c202a",
      "metadata": {},
      "outputs": [],
      "source": [
        "FEATURE_COLS = ['wellco_web_visits_count', 'days_since_last_wellco_web', 'app_sessions_count',\n",
        "                'icd_distinct_count', 'has_focus_icd', 'days_since_last_claim', 'tenure_days']\n",
        "N_SPLITS, N_CURVE_POINTS = 5, 100\n",
        "CANDIDATE_DEFS = [('S+LGBM','S','LGBM'),('S+XGB','S','XGB'),('T+LGBM','T','LGBM'),('T+XGB','T','XGB'),('X+LGBM','X','LGBM'),('X+XGB','X','XGB')]\n",
        "\n",
        "X = train_features[FEATURE_COLS].copy()\n",
        "y = train_features['churn'].astype(int).values\n",
        "treatment = train_features['outreach'].astype(int).values\n",
        "stratify_col = 2 * treatment + y\n",
        "SCALE_POS_WEIGHT = (y == 0).sum() / max((y == 1).sum(), 1)\n",
        "print('X shape:', X.shape, '| Churn rate:', y.mean(), '| Treatment rate:', treatment.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6968a36a",
      "metadata": {},
      "outputs": [],
      "source": [
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "cv_records, cv_curves, cv_segments = [], {}, {}\n",
        "for name, meta_key, base_key in CANDIDATE_DEFS:\n",
        "    cv_curves[name], cv_segments[name] = [], []\n",
        "    for fold_i, (tr_idx, va_idx) in enumerate(skf.split(X, stratify_col), start=1):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "        t_tr, t_va = treatment[tr_idx], treatment[va_idx]\n",
        "        spw = (y_tr == 0).sum() / max((y_tr == 1).sum(), 1)\n",
        "        model = _build_model(meta_key, base_key, spw)\n",
        "        model.fit(X_tr, t_tr, y_tr)\n",
        "        tau = np.asarray(model.predict(X_va)).reshape(-1)\n",
        "        ks, uvals = uplift_curve(y_va, t_va, tau, n_points=N_CURVE_POINTS)\n",
        "        auuc_val = approx_auuc(ks, uvals)\n",
        "        qini_val = float(qini_auc_score(y_va, tau, t_va)) if qini_auc_score else np.nan\n",
        "        u10, u20 = uplift_at_k(y_va, t_va, tau, 0.10), uplift_at_k(y_va, t_va, tau, 0.20)\n",
        "        seg = assign_segments(tau)\n",
        "        seg_share = pd.Series(seg).value_counts(normalize=True)\n",
        "        cv_records.append({'model': name, 'fold': fold_i, 'auuc': auuc_val, 'qini': qini_val, 'uplift@10%': u10, 'uplift@20%': u20,\n",
        "                          'persuadables_pct': seg_share.get('Persuadables', 0)})\n",
        "        cv_curves[name].append((ks, uvals))\n",
        "        cv_segments[name].append(seg_share)\n",
        "        print(f'[{name}] Fold {fold_i}: AUUC={auuc_val:+.5f} Qini={qini_val:+.5f} u@10%={u10:+.4f} u@20%={u20:+.4f}')\n",
        "print('CV complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "892c7f3b",
      "metadata": {},
      "source": [
        "### 5.5 Results summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6f77862",
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_df = pd.DataFrame(cv_records)\n",
        "summary = cv_df.groupby('model').agg(auuc_mean=('auuc','mean'), auuc_std=('auuc','std'),\n",
        "    qini_mean=('qini','mean'), u10_mean=('uplift@10%','mean'), u20_mean=('uplift@20%','mean')).sort_values('auuc_mean', ascending=False)\n",
        "print('CV results (mean ± std):')\n",
        "display(summary.round(5))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e07c677",
      "metadata": {},
      "source": [
        "### 5.6 Diagnostic plots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "models = summary.index.tolist()\n",
        "x = np.arange(len(models))\n",
        "ax1.bar(x, summary['auuc_mean'], yerr=summary['auuc_std'], capsize=5); ax1.set_xticks(x); ax1.set_xticklabels(models, rotation=30, ha='right')\n",
        "ax1.set_ylabel('AUUC'); ax1.set_title('AUUC by model'); ax1.axhline(0, color='grey', ls='--')\n",
        "qini_std = cv_df.groupby('model')['qini'].std().reindex(models).fillna(0).values\n",
        "ax2.bar(x, summary['qini_mean'], yerr=qini_std, capsize=5); ax2.set_xticks(x); ax2.set_xticklabels(models, rotation=30, ha='right')\n",
        "ax2.set_ylabel('Qini'); ax2.set_title('Qini by model'); ax2.axhline(0, color='grey', ls='--')\n",
        "plt.tight_layout(); plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
