{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d8b1b767",
      "metadata": {},
      "source": [
        "# Uplift Modeling for Churn Prediction\n",
        "\n",
        "This notebook contains the end-to-end uplift modeling workflow: exploratory data analysis (EDA), feature insights, and preparation for uplift modeling.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Setup**\n",
        "Imports and project paths. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d3e849d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core libraries\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import chi2_contingency, ttest_ind\n",
        "\n",
        "# Embedding & ML (used in section 4 – feature engineering pipeline)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Uplift modeling imports (used in model-selection section)\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "try:\n",
        "    from causalml.inference.meta import BaseSRegressor, BaseTRegressor, BaseXRegressor\n",
        "    from causalml.metrics import qini_auc_score, auuc_score\n",
        "except Exception:  # pragma: no cover - handled at runtime\n",
        "    BaseSRegressor = BaseTRegressor = BaseXRegressor = None\n",
        "    qini_auc_score = auuc_score = None\n",
        "\n",
        "try:\n",
        "    from lightgbm import LGBMRegressor\n",
        "    from xgboost import XGBRegressor\n",
        "except Exception:  # pragma: no cover - handled at runtime\n",
        "    LGBMRegressor = XGBRegressor = None\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "\n",
        "def set_axes_clear(ax, x_axis_at_zero=False):\n",
        "    \"\"\"Y-axis at x=0 (left spine). X-axis: at y=0 if x_axis_at_zero else bottom spine.\"\"\"\n",
        "    for spine in (\"top\", \"right\"):\n",
        "        ax.spines[spine].set_visible(False)\n",
        "    if x_axis_at_zero:\n",
        "        ax.spines[\"bottom\"].set_visible(False)\n",
        "    else:\n",
        "        ax.spines[\"bottom\"].set_visible(True)\n",
        "        ax.spines[\"bottom\"].set_color(\"black\")\n",
        "        ax.spines[\"bottom\"].set_linewidth(1.2)\n",
        "    ax.spines[\"left\"].set_visible(True)\n",
        "    ax.spines[\"left\"].set_color(\"black\")\n",
        "    ax.spines[\"left\"].set_linewidth(1.2)\n",
        "\n",
        "# Paths (notebook lives in project root)\n",
        "# Project root (parent of src/); files/ is at project root, not inside src\n",
        "BASE_DIR = Path(\".\").resolve().parent\n",
        "FILE_DIR = BASE_DIR / \"files\"  # all data files live under files/\n",
        "TRAIN_DIR = FILE_DIR / \"train\"\n",
        "TEST_DIR = FILE_DIR / \"test\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d654ac6e",
      "metadata": {},
      "source": [
        "## **2. Load data**\n",
        "Load training and test CSVs, restrict train event data to the observation window (July 1–15, 2025), and print shapes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88704573",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training data\n",
        "churn_labels = pd.read_csv(TRAIN_DIR / \"churn_labels.csv\", parse_dates=[\"signup_date\"])\n",
        "app_usage = pd.read_csv(TRAIN_DIR / \"app_usage.csv\", parse_dates=[\"timestamp\"])\n",
        "web_visits = pd.read_csv(TRAIN_DIR / \"web_visits.csv\", parse_dates=[\"timestamp\"])\n",
        "claims = pd.read_csv(TRAIN_DIR / \"claims.csv\", parse_dates=[\"diagnosis_date\"])\n",
        "\n",
        "# Test data\n",
        "test_members = pd.read_csv(TEST_DIR / \"test_members.csv\", parse_dates=[\"signup_date\"])\n",
        "test_app_usage = pd.read_csv(TEST_DIR / \"test_app_usage.csv\", parse_dates=[\"timestamp\"])\n",
        "test_web_visits = pd.read_csv(TEST_DIR / \"test_web_visits.csv\", parse_dates=[\"timestamp\"])\n",
        "test_claims = pd.read_csv(TEST_DIR / \"test_claims.csv\", parse_dates=[\"diagnosis_date\"])\n",
        "\n",
        "# Observation window: July 1 - July 15, 2025 (pre-outreach). Outreach = July 15; churn measured after.\n",
        "# Restrict train event data only; test data is not filtered (outreach has not occurred for test).\n",
        "OBS_START = pd.Timestamp(\"2025-07-01\")\n",
        "OBS_END   = pd.Timestamp(\"2025-07-15\")  # exclusive: keep events strictly before outreach\n",
        "\n",
        "web_visits = web_visits[(web_visits[\"timestamp\"] >= OBS_START) & (web_visits[\"timestamp\"] < OBS_END)]\n",
        "app_usage  = app_usage[(app_usage[\"timestamp\"] >= OBS_START) & (app_usage[\"timestamp\"] < OBS_END)]\n",
        "claims     = claims[(claims[\"diagnosis_date\"] >= OBS_START) & (claims[\"diagnosis_date\"] < OBS_END)]\n",
        "\n",
        "# Quick sanity check\n",
        "for name, df in {\n",
        "    \"churn_labels\": churn_labels,\n",
        "    \"app_usage\": app_usage,\n",
        "    \"web_visits\": web_visits,\n",
        "    \"claims\": claims,\n",
        "    \"test_members\": test_members,\n",
        "    \"test_app_usage\": test_app_usage,\n",
        "    \"test_web_visits\": test_web_visits,\n",
        "    \"test_claims\": test_claims,\n",
        "}.items():\n",
        "    print(f\"{name}: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca2faf3",
      "metadata": {},
      "source": [
        "**What it means:** The printed shapes show how many rows and columns each table has after loading and (for train) after restricting to the observation window. Train event tables (app_usage, web_visits, claims) are limited to events before outreach (July 15, 2025).\n",
        "\n",
        "**What it says about further analysis:** We have 10,000 train members and 10,000 test members; event volumes are large enough for aggregation. Next we explore structure and missingness, then build features from these tables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f355d10d",
      "metadata": {},
      "source": [
        "## **3. EDA**\n",
        "\n",
        "Exploratory data analysis: table structure, missingness, treatment balance, leakage checks, and uplift by engagement/claims/recency.\n",
        "\n",
        "---\n",
        "\n",
        "### **3.1 Raw data overview**\n",
        "Summarize structure, dtypes, and sample rows for all 8 tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef0f85a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.1 Raw data overview: All datasets\n",
        "# ----------\n",
        "\n",
        "def print_table_overview(name, df):\n",
        "    \"\"\"Print structure, dtypes, numeric describe, date ranges, and head for a single table.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name : str\n",
        "        Display name of the table.\n",
        "    df : pandas.DataFrame\n",
        "        The table to summarize.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  {name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"\\n--- dtypes ---\")\n",
        "    print(df.dtypes.to_string())\n",
        "    \n",
        "    # Describe only meaningful numeric columns (exclude IDs and dates)\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    # Remove member_id and other ID columns\n",
        "    numeric_cols = [col for col in numeric_cols if col not in ['member_id']]\n",
        "    \n",
        "    if len(numeric_cols) > 0:\n",
        "        print(f\"\\n--- describe (numeric columns only) ---\")\n",
        "        print(df[numeric_cols].describe().to_string())\n",
        "    \n",
        "    # Show date ranges separately\n",
        "    date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()\n",
        "    if len(date_cols) > 0:\n",
        "        print(f\"\\n--- date ranges ---\")\n",
        "        for col in date_cols:\n",
        "            print(f\"  {col}: {df[col].min()} to {df[col].max()}\")\n",
        "    \n",
        "    # Show object column summaries\n",
        "    object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "    if len(object_cols) > 0:\n",
        "        print(f\"\\n--- object columns (unique counts) ---\")\n",
        "        for col in object_cols:\n",
        "            print(f\"  {col}: {df[col].nunique()} unique values\")\n",
        "    \n",
        "    print(f\"\\n--- head(2) ---\")\n",
        "    display(df.head(2))\n",
        "\n",
        "# Apply to all tables\n",
        "all_tables = {\n",
        "    \"churn_labels\": churn_labels,\n",
        "    \"app_usage\": app_usage,\n",
        "    \"web_visits\": web_visits,\n",
        "    \"claims\": claims,\n",
        "    \"test_members\": test_members,\n",
        "    \"test_app_usage\": test_app_usage,\n",
        "    \"test_web_visits\": test_web_visits,\n",
        "    \"test_claims\": test_claims,\n",
        "}\n",
        "\n",
        "for name, df in all_tables.items():\n",
        "    print_table_overview(name, df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fce9c9f",
      "metadata": {},
      "source": [
        "**What it means:** For each of the 8 tables we see column types, numeric summaries (where applicable), date ranges, unique counts for object columns, and a 2-row sample. This confirms churn_labels has churn/outreach, event tables have timestamps, and web_visits has url/title/description.\n",
        "\n",
        "**What it says about further analysis:** We have a clear picture of schema and value ranges. Use this to design aggregates (e.g. counts per member from event tables) and to handle dates consistently. Next: column-specific checks (event_type, url, title, icd_code)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f07fbe1",
      "metadata": {},
      "source": [
        "### **3.1 Column-specific checks**\n",
        "Check `event_type`, `url`, `title`, and `icd_code` to guide feature engineering (e.g. drop constant columns, use title/description for content features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a887d80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.1 Column-specific checks\n",
        "# Purpose: Check special columns (event_type, url, title, icd_code) for feature engineering decisions.\n",
        "# What we test: value_counts for event_type, url, title, icd_code.\n",
        "# What we do with this info:\n",
        "#   - If event_type is constant -> drop it.\n",
        "#   - URL/title variety -> potential content-categorization features.\n",
        "#   - ICD distribution -> guides focus-ICD flag design.\n",
        "# ----------\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"  Column-specific checks\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\napp_usage event_type value_counts:\")\n",
        "print(app_usage[\"event_type\"].value_counts().to_string())\n",
        "print(f\"  -> {'CONSTANT — can drop' if app_usage['event_type'].nunique() == 1 else 'MULTIPLE VALUES — keep'}\")\n",
        "\n",
        "# url and title in web_visits: content variety\n",
        "print(f\"\\nweb_visits url: {web_visits['url'].nunique()} unique values\")\n",
        "print(\"  Top-5 URLs:\")\n",
        "print(web_visits[\"url\"].value_counts().head(5).to_string())\n",
        "print(f\"\\nweb_visits title: {web_visits['title'].nunique()} unique values\")\n",
        "print(\"  Top-5 titles:\")\n",
        "print(web_visits[\"title\"].value_counts().head(5).to_string())\n",
        "\n",
        "# icd_code in claims\n",
        "print(f\"\\nclaims icd_code: {claims['icd_code'].nunique()} unique values\")\n",
        "print(\"  Top-10 ICD codes:\")\n",
        "print(claims[\"icd_code\"].value_counts().head(10).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97097e28",
      "metadata": {},
      "source": [
        "**What it means:** `event_type` is constant (\"session\") so it can be dropped. URLs are very diverse; titles/descriptions have limited unique values and are good candidates for embedding-based relevance. ICD codes are well distributed for focus-ICD flags.\n",
        "\n",
        "**What it says about further analysis:** Drop `event_type` in feature engineering. Use `title` and `description` (not URL) for health-related web classification via embeddings. Build focus-ICD binary/count features from the ICD distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6a85cb",
      "metadata": {},
      "source": [
        "### **3.2 Missing values and member coverage**\n",
        "Check column-level nulls and how many members have no rows in each activity source (web, app, claims)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b864977c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.2 Missing values and member coverage\n",
        "# Purpose: Find all missing data — both nulls within tables and members absent\n",
        "#   from activity sources. This determines our imputation strategy.\n",
        "# What we test:\n",
        "#   Part A: .isnull().sum() per column for all 8 tables.\n",
        "#   Part B: For train and test base sets, count members with zero rows in each\n",
        "#           source (web, app, claims). Cross-source pattern.\n",
        "# What we do with this info:\n",
        "#   - If column nulls exist -> decide imputation method.\n",
        "#   - Members absent from a source -> their aggregated features will be NaN\n",
        "#     after join. Must zero-fill or handle explicitly.\n",
        "#   - Cross-source patterns -> if absence is correlated, a single \"inactive\"\n",
        "#     flag may suffice.\n",
        "# Plots: 1 bar chart (% absent per source with annotations).\n",
        "# ----------\n",
        "\n",
        "# --- Part A: Column-level null check ---\n",
        "print(\"=\"*60)\n",
        "print(\"  Part A — Column-level null check\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "null_rows = []\n",
        "for name, df in all_tables.items():\n",
        "    nulls = df.isnull().sum()\n",
        "    for col, cnt in nulls.items():\n",
        "        if cnt > 0:\n",
        "            null_rows.append({\"table\": name, \"column\": col, \"null_count\": cnt})\n",
        "\n",
        "if null_rows:\n",
        "    null_df = pd.DataFrame(null_rows)\n",
        "    print(null_df.to_string(index=False))\n",
        "else:\n",
        "    print(\"\\n✓ No null values found in any column of any table.\\n\")\n",
        "\n",
        "# --- Part B: Member coverage across activity sources ---\n",
        "print(\"=\"*60)\n",
        "print(\"  Part B — Member coverage across sources\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for split_name, base_df, src_tables in [\n",
        "    (\"TRAIN\", churn_labels, {\"web_visits\": web_visits, \"app_usage\": app_usage, \"claims\": claims}),\n",
        "    (\"TEST\",  test_members,  {\"web_visits\": test_web_visits, \"app_usage\": test_app_usage, \"claims\": test_claims}),\n",
        "]:\n",
        "    base_ids = set(base_df[\"member_id\"].unique())\n",
        "    n_base = len(base_ids)\n",
        "    print(f\"\\n--- {split_name} (base members: {n_base}) ---\")\n",
        "\n",
        "    source_sets = {}\n",
        "    coverage_rows = []\n",
        "    for src_name, src_df in src_tables.items():\n",
        "        present = set(src_df[\"member_id\"].unique())\n",
        "        source_sets[src_name] = present\n",
        "        missing = len(base_ids - present)\n",
        "        coverage_rows.append({\n",
        "            \"source\": src_name,\n",
        "            \"members_present\": len(present & base_ids),\n",
        "            \"members_absent\": missing,\n",
        "            \"absent_pct\": missing / n_base * 100,\n",
        "        })\n",
        "\n",
        "    cov = pd.DataFrame(coverage_rows)\n",
        "    print(cov.to_string(index=False))\n",
        "\n",
        "    # Cross-source pattern (train only)\n",
        "    if split_name == \"TRAIN\":\n",
        "        has_web = source_sets[\"web_visits\"] & base_ids\n",
        "        has_app = source_sets[\"app_usage\"] & base_ids\n",
        "        has_claims = source_sets[\"claims\"] & base_ids\n",
        "        no_web = base_ids - has_web\n",
        "        no_app = base_ids - has_app\n",
        "        no_claims = base_ids - has_claims\n",
        "\n",
        "        patterns = {\n",
        "            \"missing web only\":     len(no_web - no_app - no_claims),\n",
        "            \"missing app only\":     len(no_app - no_web - no_claims),\n",
        "            \"missing claims only\":  len(no_claims - no_web - no_app),\n",
        "            \"missing web+app\":      len(no_web & no_app - no_claims),\n",
        "            \"missing web+claims\":   len(no_web & no_claims - no_app),\n",
        "            \"missing app+claims\":   len(no_app & no_claims - no_web),\n",
        "            \"missing all 3\":        len(no_web & no_app & no_claims),\n",
        "            \"present in all\":       len(has_web & has_app & has_claims),\n",
        "        }\n",
        "        print(\"\\nCross-source missingness patterns (train):\")\n",
        "        for pat, cnt in patterns.items():\n",
        "            print(f\"  {pat}: {cnt} ({cnt/n_base*100:.2f}%)\")\n",
        "\n",
        "        # --- Bar chart: % absent per source (train) ---\n",
        "        fig, ax = plt.subplots(figsize=(7, 4))\n",
        "        bars = ax.bar(cov[\"source\"], cov[\"absent_pct\"], color=sns.color_palette()[:3])\n",
        "        ax.set_ylabel(\"% with zero activity\", fontsize=11)\n",
        "        ax.set_xlabel(\"Source table\")\n",
        "        ax.set_title(\"Members absent from each activity source (train)\")\n",
        "        for bar, row in zip(bars, cov.itertuples()):\n",
        "            ax.annotate(f\"{row.members_absent}\\n({row.absent_pct:.2f}%)\",\n",
        "                        xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                        ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "        set_axes_clear(ax, x_axis_at_zero=False)\n",
        "        fig.subplots_adjust(left=0.22, right=0.96, top=0.92, bottom=0.12)\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab50e69f",
      "metadata": {},
      "source": [
        "**What it means:** No column-level nulls in any table. A small share of members have zero rows in each source (e.g. ~0.25% missing web, ~0.02% missing app). Almost all members appear in all three sources; absence is mostly per-source, not overlapping.\n",
        "\n",
        "**What it says about further analysis:** Zero-fill aggregated features for members missing from a source. Optional: add binary flags like `has_web_visits` if we find that absence is predictive of churn or uplift. Next: test whether missingness is related to churn/outreach (3.3)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "039cc5c7",
      "metadata": {},
      "source": [
        "### **3.3 Missingness mechanism**\n",
        "Test whether absence from each activity source is associated with churn or outreach (Chi-square). If yes, missingness is informative and we should consider has_X flags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec212f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.3 Missingness mechanism (MCAR / MAR / MNAR)\n",
        "# Purpose: Understand *why* some members are absent from activity sources.\n",
        "#   If absence correlates with churn/outreach, the missingness itself\n",
        "#   is informative (MAR/MNAR) and we should create has_X flags as features.\n",
        "#   If not (MCAR), simple zero-fill is fine.\n",
        "# What we test:\n",
        "#   1. Churn rate for present vs absent members, per source (Chi-square).\n",
        "#   2. Outreach rate for present vs absent, per source (Chi-square).\n",
        "#   3. Cross-source contingency table.\n",
        "# Plots: 1 grouped bar chart — churn rate for \"has activity\" vs \"no activity\"\n",
        "#   per source. Key visual to judge whether absence is informative.\n",
        "# What we do with this info:\n",
        "#   - If churn differs significantly by presence → create has_X binary flag.\n",
        "#   - If not → zero-fill engagement features is sufficient.\n",
        "# ----------\n",
        "\n",
        "# Build has_X flags on train base\n",
        "train_ids = churn_labels[[\"member_id\", \"churn\", \"outreach\"]].copy()\n",
        "\n",
        "web_ids = set(web_visits[\"member_id\"].unique())\n",
        "app_ids = set(app_usage[\"member_id\"].unique())\n",
        "claims_ids = set(claims[\"member_id\"].unique())\n",
        "\n",
        "train_ids[\"has_web\"] = train_ids[\"member_id\"].isin(web_ids).astype(int)\n",
        "train_ids[\"has_app\"] = train_ids[\"member_id\"].isin(app_ids).astype(int)\n",
        "train_ids[\"has_claims\"] = train_ids[\"member_id\"].isin(claims_ids).astype(int)\n",
        "\n",
        "# --- 1 & 2: Chi-square tests ---\n",
        "results = []\n",
        "for source in [\"has_web\", \"has_app\", \"has_claims\"]:\n",
        "    for target in [\"churn\", \"outreach\"]:\n",
        "        ct = pd.crosstab(train_ids[source], train_ids[target])\n",
        "        chi2, p, dof, expected = chi2_contingency(ct)\n",
        "        rate_absent = train_ids.loc[train_ids[source] == 0, target].mean()\n",
        "        rate_present = train_ids.loc[train_ids[source] == 1, target].mean()\n",
        "        results.append({\n",
        "            \"source_flag\": source,\n",
        "            \"target\": target,\n",
        "            \"rate_absent (0)\": round(rate_absent, 4) if pd.notna(rate_absent) else \"N/A\",\n",
        "            \"rate_present (1)\": round(rate_present, 4),\n",
        "            \"chi2\": round(chi2, 2),\n",
        "            \"p_value\": f\"{p:.4g}\",\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"=\"*70)\n",
        "print(\"  Chi-square tests: churn/outreach rate by presence/absence\")\n",
        "print(\"=\"*70)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# --- 3: Cross-source contingency ---\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"  Cross-source contingency (train)\")\n",
        "print(\"=\"*70)\n",
        "cross = train_ids.groupby([\"has_web\", \"has_app\", \"has_claims\"]).size().reset_index(name=\"count\")\n",
        "print(cross.to_string(index=False))\n",
        "\n",
        "# --- Grouped bar chart: churn rate present vs absent per source ---\n",
        "chart_data = []\n",
        "for source in [\"has_web\", \"has_app\", \"has_claims\"]:\n",
        "    for val, label in [(1, \"present\"), (0, \"absent\")]:\n",
        "        subset = train_ids[train_ids[source] == val]\n",
        "        if len(subset) > 0:\n",
        "            chart_data.append({\n",
        "                \"source\": source.replace(\"has_\", \"\"),\n",
        "                \"group\": label,\n",
        "                \"churn_rate\": subset[\"churn\"].mean(),\n",
        "                \"n\": len(subset),\n",
        "            })\n",
        "\n",
        "chart_df = pd.DataFrame(chart_data)\n",
        "if len(chart_df) > 0:\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    sources = chart_df[\"source\"].unique()\n",
        "    x = np.arange(len(sources))\n",
        "    width = 0.35\n",
        "\n",
        "    present = chart_df[chart_df[\"group\"] == \"present\"].set_index(\"source\")\n",
        "    absent = chart_df[chart_df[\"group\"] == \"absent\"].set_index(\"source\")\n",
        "\n",
        "    bars1 = ax.bar(x - width/2,\n",
        "                   [present.loc[s, \"churn_rate\"] if s in present.index else 0 for s in sources],\n",
        "                   width, label=\"Has activity\", color=sns.color_palette()[0])\n",
        "    bars2 = ax.bar(x + width/2,\n",
        "                   [absent.loc[s, \"churn_rate\"] if s in absent.index else 0 for s in sources],\n",
        "                   width, label=\"No activity\", color=sns.color_palette()[3])\n",
        "\n",
        "    ax.set_ylabel(\"Churn rate\")\n",
        "    ax.set_xlabel(\"Activity source\")\n",
        "    ax.set_title(\"Churn rate: members with vs without activity per source\")\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(sources)\n",
        "    ax.legend()\n",
        "    set_axes_clear(ax, x_axis_at_zero=False)\n",
        "\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            h = bar.get_height()\n",
        "            if h > 0:\n",
        "                ax.annotate(f\"{h:.3f}\",\n",
        "                            xy=(bar.get_x() + bar.get_width()/2, h),\n",
        "                            ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7b4bc86",
      "metadata": {},
      "source": [
        "**What it means:** Chi-square p-values and the bar chart show whether churn (or outreach) rate differs between members who have activity in a source vs those who do not. The cross-tab shows how many members are missing from each combination of sources.\n",
        "\n",
        "**What it says about further analysis:**  p-values are large (e.g. > 0.05), missingness is not strongly related to churn/outreach → zero-fill is enough."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e70ae30",
      "metadata": {},
      "source": [
        "### **3.4 Labels and treatment balance**\n",
        "Check churn rate, outreach rate, and group sizes. Affects metric choice and model design."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2cab11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.4 Labels and treatment balance\n",
        "# Purpose: Assess churn class imbalance and outreach/control balance.\n",
        "#   These directly affect metric choice and model design.\n",
        "# What we test:\n",
        "#   - Overall churn rate, outreach rate, group sizes.\n",
        "#   - Outreach × churn cross-tabulation.\n",
        "# Plots:\n",
        "#   1. sns.countplot for outreach (0/1).\n",
        "#   2. sns.countplot for churn (0/1).\n",
        "#   3. sns.barplot churn rate by outreach group.\n",
        "# What we do with this info:\n",
        "#   - ~20% churn → class imbalance → consider stratified sampling / proper metric.\n",
        "#   - ~40% outreach → decent treatment group size for uplift estimation.\n",
        "# ----------\n",
        "\n",
        "churn_rate = churn_labels[\"churn\"].mean()\n",
        "outreach_rate = churn_labels[\"outreach\"].mean()\n",
        "\n",
        "summary_labels = churn_labels.groupby(\"outreach\")[\"churn\"].agg([\n",
        "    (\"members\", \"count\"),\n",
        "    (\"churn_rate\", \"mean\"),\n",
        "])\n",
        "\n",
        "print(f\"Overall churn rate: {churn_rate:.3f}\")\n",
        "print(f\"Outreach rate: {outreach_rate:.3f}\")\n",
        "print(\"\\nOutreach x Churn cross-tabulation:\")\n",
        "cross_tab = pd.crosstab(churn_labels[\"outreach\"], churn_labels[\"churn\"],\n",
        "                        margins=True, margins_name=\"Total\")\n",
        "print(cross_tab.to_string())\n",
        "print(\"\\nChurn rates by group:\")\n",
        "print(summary_labels.to_string())\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=churn_labels, x=\"outreach\")\n",
        "plt.title(\"Outreach vs. control counts\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Outreach\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.tick_params(labelsize=11)\n",
        "set_axes_clear(plt.gca(), x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=churn_labels, x=\"churn\")\n",
        "plt.title(\"Churn label counts\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Churn\", fontsize=12)\n",
        "plt.ylabel(\"Count\", fontsize=12)\n",
        "plt.tick_params(labelsize=11)\n",
        "set_axes_clear(plt.gca(), x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=summary_labels.reset_index(), x=\"outreach\", y=\"churn_rate\")\n",
        "plt.title(\"Churn rate by outreach group\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Outreach\", fontsize=12)\n",
        "plt.ylabel(\"Churn rate\", fontsize=12)\n",
        "plt.tick_params(labelsize=11)\n",
        "set_axes_clear(plt.gca(), x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e9378e",
      "metadata": {},
      "source": [
        "**What it means:** We see overall churn rate (~20%), outreach rate (~40%), and how churn varies between treated vs control. Plots show balance and raw churn by group.\n",
        "\n",
        "**What it says about further analysis:** Class imbalance in churn suggests using stratified sampling or appropriate metrics (e.g. AUUC for uplift). Treatment group size is sufficient for estimating uplift. Next: validate time windows and check for leakage (3.5)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6e15f4b",
      "metadata": {},
      "source": [
        "### **3.5 Leakage & time-window validation**\n",
        "Confirm event timestamps fall within the observation window and do not precede signup (no leakage)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e956a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----------\n",
        "# 3.5 Leakage & time-window validation\n",
        "# Purpose: Validate event timestamps vs signup dates and summarize observation windows.\n",
        "# Event data is already restricted to [OBS_START, OBS_END) in Section 2 (Load data).\n",
        "# ----------\n",
        "\n",
        "# Global observation end (max event date across sources)\n",
        "obs_end = max(\n",
        "    web_visits[\"timestamp\"].max(),\n",
        "    app_usage[\"timestamp\"].max(),\n",
        "    claims[\"diagnosis_date\"].max(),\n",
        ")\n",
        "\n",
        "# Summary of min/max timestamps per table\n",
        "window_summary = pd.DataFrame([\n",
        "    {\n",
        "        \"table\": \"web_visits\",\n",
        "        \"min_ts\": web_visits[\"timestamp\"].min(),\n",
        "        \"max_ts\": web_visits[\"timestamp\"].max(),\n",
        "        \"rows\": len(web_visits),\n",
        "    },\n",
        "    {\n",
        "        \"table\": \"app_usage\",\n",
        "        \"min_ts\": app_usage[\"timestamp\"].min(),\n",
        "        \"max_ts\": app_usage[\"timestamp\"].max(),\n",
        "        \"rows\": len(app_usage),\n",
        "    },\n",
        "    {\n",
        "        \"table\": \"claims\",\n",
        "        \"min_ts\": claims[\"diagnosis_date\"].min(),\n",
        "        \"max_ts\": claims[\"diagnosis_date\"].max(),\n",
        "        \"rows\": len(claims),\n",
        "    },\n",
        "])\n",
        "\n",
        "# Count events that occur before signup_date (possible leakage or data issues)\n",
        "\n",
        "def count_events_before_signup(events_df, date_col, labels_df):\n",
        "    \"\"\"Count event rows where event date is before the member's signup_date (potential leakage).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    events_df : pandas.DataFrame\n",
        "        Event table with member_id and date_col.\n",
        "    date_col : str\n",
        "        Name of the date column (e.g. 'timestamp' or 'diagnosis_date').\n",
        "    labels_df : pandas.DataFrame\n",
        "        Table with member_id and signup_date.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        Number of event rows where event date < signup_date.\n",
        "    \"\"\"\n",
        "    merged = events_df[[\"member_id\", date_col]].merge(\n",
        "        labels_df[[\"member_id\", \"signup_date\"]], on=\"member_id\", how=\"left\"\n",
        "    )\n",
        "    return (merged[date_col] < merged[\"signup_date\"]).sum()\n",
        "\n",
        "leakage_checks = pd.DataFrame([\n",
        "    {\n",
        "        \"table\": \"web_visits\",\n",
        "        \"events_before_signup\": count_events_before_signup(web_visits, \"timestamp\", churn_labels),\n",
        "    },\n",
        "    {\n",
        "        \"table\": \"app_usage\",\n",
        "        \"events_before_signup\": count_events_before_signup(app_usage, \"timestamp\", churn_labels),\n",
        "    },\n",
        "    {\n",
        "        \"table\": \"claims\",\n",
        "        \"events_before_signup\": count_events_before_signup(claims, \"diagnosis_date\", churn_labels),\n",
        "    },\n",
        "])\n",
        "\n",
        "window_summary, leakage_checks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157ccf02",
      "metadata": {},
      "source": [
        "**What it means:** The first table shows min/max timestamps per event table (all within July 1–14, 2025). The second table shows zero events before signup for web, app, and claims — no leakage.\n",
        "\n",
        "**What it says about further analysis:** Observation window and signup logic are consistent. We can safely use these events for feature engineering. Next: temporal and engagement uplift (3.6, 3.7)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db5929b2",
      "metadata": {},
      "source": [
        "### **3.6 Temporal features as uplift moderators**\n",
        "\n",
        "Uplift = P(churn=1 | outreach=1, bin) − P(churn=1 | outreach=0, bin).\n",
        "\n",
        "Each bar shows uplift among members who had **at least one event** in that bin. The same member may appear in multiple bins.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aeeaf8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.6 – Data preparation: extract temporal features from web + app events.\n",
        "\n",
        "web_ev = web_visits[[\"member_id\", \"timestamp\"]].copy()\n",
        "web_ev[\"hour\"] = web_ev[\"timestamp\"].dt.hour\n",
        "web_ev[\"dow\"] = web_ev[\"timestamp\"].dt.dayofweek  # 0=Mon … 6=Sun\n",
        "\n",
        "app_ev = app_usage[[\"member_id\", \"timestamp\"]].copy()\n",
        "app_ev[\"hour\"] = app_ev[\"timestamp\"].dt.hour\n",
        "app_ev[\"dow\"] = app_ev[\"timestamp\"].dt.dayofweek\n",
        "\n",
        "events = pd.concat([\n",
        "    web_ev[[\"member_id\", \"hour\", \"dow\"]],\n",
        "    app_ev[[\"member_id\", \"hour\", \"dow\"]],\n",
        "], ignore_index=True)\n",
        "\n",
        "def time_bin(h):\n",
        "    \"\"\"Map hour (0-23) to a time-of-day label for aggregation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    h : int\n",
        "        Hour of day (0-23).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        One of 'Early Morning', 'Morning', 'Afternoon', 'Evening'.\n",
        "    \"\"\"\n",
        "    if h < 6:  return \"Early Morning\"\n",
        "    if h < 12: return \"Morning\"\n",
        "    if h < 18: return \"Afternoon\"\n",
        "    return \"Evening\"\n",
        "\n",
        "events[\"time_of_day\"] = events[\"hour\"].apply(time_bin)\n",
        "\n",
        "DOW_NAMES = {0: \"Mon\", 1: \"Tue\", 2: \"Wed\", 3: \"Thu\", 4: \"Fri\", 5: \"Sat\", 6: \"Sun\"}\n",
        "events[\"dow_name\"] = events[\"dow\"].map(DOW_NAMES)\n",
        "events[\"is_weekend\"] = events[\"dow\"].isin([5, 6])\n",
        "\n",
        "labels = churn_labels[[\"member_id\", \"churn\", \"outreach\"]]\n",
        "\n",
        "print(f\"Events prepared: {len(events):,} rows from {events['member_id'].nunique():,} members\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93923f77",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reusable uplift helper – used by all uplift bar plots in 3.6 / 3.7 / 3.8.\n",
        "\n",
        "def compute_uplift(member_ids):\n",
        "    \"\"\"Return (uplift, n_treated, n_control) for a set of member IDs.\"\"\"\n",
        "    df = labels[labels[\"member_id\"].isin(member_ids)]\n",
        "    tr = df[df[\"outreach\"] == 1][\"churn\"]\n",
        "    co = df[df[\"outreach\"] == 0][\"churn\"]\n",
        "    uplift = tr.mean() - co.mean() if len(tr) > 0 and len(co) > 0 else np.nan\n",
        "    return uplift, len(tr), len(co)\n",
        "\n",
        "\n",
        "def plot_uplift_bars(bin_names, uplifts, title, xlabel):\n",
        "    \"\"\"Simple bar plot: one bar per bin, y = uplift, horizontal zero line.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.bar(range(len(bin_names)), uplifts, color=\"steelblue\", edgecolor=\"black\", alpha=0.85)\n",
        "    ax.axhline(0, color=\"black\", linestyle=\"-\", linewidth=1.2)\n",
        "    ax.set_xticks(range(len(bin_names)))\n",
        "    ax.set_xticklabels(bin_names, rotation=20, ha=\"right\")\n",
        "    ax.set_xlabel(xlabel, fontsize=12)\n",
        "    ax.set_ylabel(\"Uplift (churn-rate difference)\", fontsize=12)\n",
        "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
        "    ax.grid(axis=\"y\", alpha=0.3)\n",
        "    set_axes_clear(ax, x_axis_at_zero=True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "695ae13f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.6a – Uplift by time of day\n",
        "\n",
        "tod_order = [\"Early Morning\", \"Morning\", \"Afternoon\", \"Evening\"]\n",
        "tod_uplift, tod_nt, tod_nc = [], [], []\n",
        "\n",
        "for tod in tod_order:\n",
        "    ids = events.loc[events[\"time_of_day\"] == tod, \"member_id\"].unique()\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    tod_uplift.append(u); tod_nt.append(nt); tod_nc.append(nc)\n",
        "\n",
        "plot_uplift_bars(tod_order, tod_uplift,\n",
        "                 title=\"Uplift by time of day\",\n",
        "                 xlabel=\"Time of day\")\n",
        "\n",
        "print(f\"{'Group':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(tod_order, tod_uplift, tod_nt, tod_nc):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e50683b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.6b – Uplift by day of week\n",
        "\n",
        "dow_order = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
        "dow_uplift, dow_nt, dow_nc = [], [], []\n",
        "\n",
        "for day in dow_order:\n",
        "    ids = events.loc[events[\"dow_name\"] == day, \"member_id\"].unique()\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    dow_uplift.append(u); dow_nt.append(nt); dow_nc.append(nc)\n",
        "\n",
        "plot_uplift_bars(dow_order, dow_uplift,\n",
        "                 title=\"Uplift by day of week\",\n",
        "                 xlabel=\"Day of week\")\n",
        "\n",
        "print(f\"{'Group':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(dow_order, dow_uplift, dow_nt, dow_nc):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abdc9470",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.6c – Uplift by weekend vs weekday\n",
        "\n",
        "wk_labels = [\"Weekday\", \"Weekend\"]\n",
        "wk_uplift, wk_nt, wk_nc = [], [], []\n",
        "\n",
        "for is_wknd in [False, True]:\n",
        "    ids = events.loc[events[\"is_weekend\"] == is_wknd, \"member_id\"].unique()\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    wk_uplift.append(u); wk_nt.append(nt); wk_nc.append(nc)\n",
        "\n",
        "plot_uplift_bars(wk_labels, wk_uplift,\n",
        "                 title=\"Uplift by weekend vs weekday\",\n",
        "                 xlabel=\"Day type\")\n",
        "\n",
        "print(f\"{'Group':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(wk_labels, wk_uplift, wk_nt, wk_nc):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "288f446e",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by time of day and by weekday vs weekend is similar across bins (all slightly negative). Outreach reduces churn a bit regardless of when members are active.\n",
        "\n",
        "**What it says about further analysis:** Temporal features (time of day, day of week, weekend) do not strongly moderate uplift. Next: engagement and claims (3.7, 3.8)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab44211",
      "metadata": {},
      "source": [
        "### **3.7 Engagement features as uplift moderators**\n",
        "\n",
        "**(a)** Distribution sanity checks — log-scaled histograms and quantile summaries.  \n",
        "**(b)** Uplift by engagement quartile for each feature.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408ec612",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.7a – Distribution sanity checks (engagement)\n",
        "\n",
        "web_per = web_visits.groupby(\"member_id\").size().rename(\"web_visits_count\").reset_index()\n",
        "app_per = app_usage.groupby(\"member_id\").size().rename(\"app_sessions_count\").reset_index()\n",
        "url_div = web_visits.groupby(\"member_id\")[\"url\"].nunique().rename(\"url_nunique\").reset_index()\n",
        "\n",
        "eng = churn_labels[[\"member_id\", \"churn\", \"outreach\"]].merge(\n",
        "    web_per, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    app_per, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    url_div, on=\"member_id\", how=\"left\"\n",
        ")\n",
        "for col in [\"web_visits_count\", \"app_sessions_count\", \"url_nunique\"]:\n",
        "    eng[col] = eng[col].fillna(0)\n",
        "\n",
        "# Quantile summaries\n",
        "for feat in [\"web_visits_count\", \"app_sessions_count\", \"url_nunique\"]:\n",
        "    print(f\"\\n{feat}:\")\n",
        "    print(eng[feat].quantile([0, .25, .5, .75, .9, .95, .99, 1]).to_string())\n",
        "\n",
        "# Log-scaled histograms\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "for i, feat in enumerate([\"web_visits_count\", \"app_sessions_count\", \"url_nunique\"]):\n",
        "    axes[i].hist(np.log1p(eng[feat]), bins=50, edgecolor=\"black\", alpha=0.7)\n",
        "    axes[i].set_xlabel(f\"log(1 + {feat})\", fontsize=11)\n",
        "    axes[i].set_ylabel(\"Number of members\", fontsize=11)\n",
        "    axes[i].set_title(feat, fontsize=12, fontweight=\"bold\")\n",
        "    axes[i].grid(alpha=0.3)\n",
        "    set_axes_clear(axes[i], x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8263b0ab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.7b – Uplift by web_visits_count quartile\n",
        "\n",
        "eng[\"web_q\"] = pd.qcut(eng[\"web_visits_count\"], q=4, duplicates=\"drop\")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(eng[\"web_q\"].dropna().unique()):\n",
        "    ids = eng.loc[eng[\"web_q\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by web visits quartile\",\n",
        "                 xlabel=\"Web visits (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beabb01d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.7c – Uplift by app_sessions_count quartile\n",
        "\n",
        "eng[\"app_q\"] = pd.qcut(eng[\"app_sessions_count\"], q=4, duplicates=\"drop\")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(eng[\"app_q\"].dropna().unique()):\n",
        "    ids = eng.loc[eng[\"app_q\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by app sessions quartile\",\n",
        "                 xlabel=\"App sessions (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86dce0c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.7d – Uplift by URL diversity quartile\n",
        "\n",
        "eng[\"url_q\"] = pd.qcut(eng[\"url_nunique\"], q=4, duplicates=\"drop\")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(eng[\"url_q\"].dropna().unique()):\n",
        "    ids = eng.loc[eng[\"url_q\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by URL diversity quartile\",\n",
        "                 xlabel=\"Unique URLs (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d14668df",
      "metadata": {},
      "source": [
        "**What it means:** Engagement (event counts, sessions, URL diversity) shows uplift varying by quartile; some bins have near-zero or slightly positive uplift.\n",
        "\n",
        "**What it says about further analysis:** Engagement level can moderate uplift — useful as features for the model. Next: claims (3.8) and recency/tenure (3.9)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b3437cc",
      "metadata": {},
      "source": [
        "### **3.8 Claims features as uplift moderators**\n",
        "\n",
        "**(a)** Distribution sanity checks — log-scaled histograms, quantile summaries, focus-ICD prevalence.  \n",
        "**(b)** Uplift by claims strata: quartile bins for counts, binary for has-focus-ICD, and 0/1/2/3 for count of focus ICDs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84cae13d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.8a – Distribution sanity checks (claims)\n",
        "\n",
        "claims_per = claims.groupby(\"member_id\").size().rename(\"claims_count\").reset_index()\n",
        "icd_nun = claims.groupby(\"member_id\")[\"icd_code\"].nunique().rename(\"icd_nunique\").reset_index()\n",
        "\n",
        "icd_focus_codes = [\"E11.9\", \"I10\", \"Z71.3\"]\n",
        "claims_f = claims.copy()\n",
        "claims_f[\"is_focus\"] = claims_f[\"icd_code\"].isin(icd_focus_codes)\n",
        "\n",
        "# Binary flag: has any focus ICD\n",
        "focus_any = claims_f.groupby(\"member_id\")[\"is_focus\"].any().rename(\"has_focus_icd\").reset_index()\n",
        "\n",
        "# Count of distinct focus ICDs per member (0, 1, 2, or 3)\n",
        "focus_count = (\n",
        "    claims_f[claims_f[\"is_focus\"]]\n",
        "    .groupby(\"member_id\")[\"icd_code\"]\n",
        "    .nunique()\n",
        "    .rename(\"focus_icd_count\")\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "cl = churn_labels[[\"member_id\", \"churn\", \"outreach\"]].merge(\n",
        "    claims_per, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    icd_nun, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    focus_any, on=\"member_id\", how=\"left\"\n",
        ").merge(\n",
        "    focus_count, on=\"member_id\", how=\"left\"\n",
        ")\n",
        "cl[\"claims_count\"] = cl[\"claims_count\"].fillna(0)\n",
        "cl[\"icd_nunique\"] = cl[\"icd_nunique\"].fillna(0)\n",
        "cl[\"has_focus_icd\"] = cl[\"has_focus_icd\"].fillna(False).astype(int)\n",
        "cl[\"focus_icd_count\"] = cl[\"focus_icd_count\"].fillna(0).astype(int)\n",
        "\n",
        "# Quantile summaries\n",
        "for feat in [\"claims_count\", \"icd_nunique\"]:\n",
        "    print(f\"\\n{feat}:\")\n",
        "    print(cl[feat].quantile([0, .25, .5, .75, .9, .95, .99, 1]).to_string())\n",
        "\n",
        "print(f\"\\nFocus-ICD prevalence: {cl['has_focus_icd'].mean():.3f}\")\n",
        "print(f\"\\nFocus-ICD count distribution:\")\n",
        "print(cl[\"focus_icd_count\"].value_counts().sort_index().to_string())\n",
        "\n",
        "# Log-scaled histograms\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "for i, feat in enumerate([\"claims_count\", \"icd_nunique\"]):\n",
        "    axes[i].hist(np.log1p(cl[feat]), bins=50, edgecolor=\"black\", alpha=0.7, color=\"green\")\n",
        "    axes[i].set_xlabel(f\"log(1 + {feat})\", fontsize=11)\n",
        "    axes[i].set_ylabel(\"Number of members\", fontsize=11)\n",
        "    axes[i].set_title(feat, fontsize=12, fontweight=\"bold\")\n",
        "    axes[i].grid(alpha=0.3)\n",
        "    set_axes_clear(axes[i], x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f5303ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.8b – Uplift by claims_count quartile\n",
        "\n",
        "cl[\"claims_q\"] = pd.qcut(cl[\"claims_count\"], q=4, duplicates=\"drop\")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(cl[\"claims_q\"].dropna().unique()):\n",
        "    ids = cl.loc[cl[\"claims_q\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by claims count quartile\",\n",
        "                 xlabel=\"Claims count (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f18a5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.8c – Uplift by icd_nunique quartile\n",
        "\n",
        "cl[\"icd_q\"] = pd.qcut(cl[\"icd_nunique\"], q=4, duplicates=\"drop\")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(cl[\"icd_q\"].dropna().unique()):\n",
        "    ids = cl.loc[cl[\"icd_q\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by distinct ICD codes quartile\",\n",
        "                 xlabel=\"Distinct ICD codes (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5718920a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.8d – Uplift by has focus ICD (binary: No / Yes)\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for val, name in [(0, \"No focus ICD\"), (1, \"Has focus ICD\")]:\n",
        "    ids = cl.loc[cl[\"has_focus_icd\"] == val, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(name); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by has focus ICD\",\n",
        "                 xlabel=\"Focus ICD status\")\n",
        "\n",
        "print(f\"{'Group':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c541152",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.8e – Uplift by count of focus ICDs (0, 1, 2, 3)\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for cnt in [0, 1, 2, 3]:\n",
        "    ids = cl.loc[cl[\"focus_icd_count\"] == cnt, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(f\"{cnt} focus ICD\"); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by count of focus ICDs\",\n",
        "                 xlabel=\"Number of distinct focus ICD codes\")\n",
        "\n",
        "print(f\"{'Group':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742f858d",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by claims (count, focus ICD, quartiles) varies across groups; some segments show stronger or weaker outreach effects.\n",
        "\n",
        "**What it says about further analysis:** Claims-based features are useful for targeting. Next: recency and tenure (3.9)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31b1cd9b",
      "metadata": {},
      "source": [
        "### **3.9 Recency and tenure features as uplift moderators**\n",
        "\n",
        "Derived features: days since last web/app/claims/any activity, tenure in days, and a binary \"recent activity within 7 days\" flag.\n",
        "All computed from a single reusable function so the same logic applies to train and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd21af00",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9 – Build recency & tenure features (reusable for train and test)\n",
        "\n",
        "def build_recency_tenure(members_df, web_df, app_df, claims_df):\n",
        "    \"\"\"\n",
        "    Build member-level recency and tenure features.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    members_df : DataFrame with at least member_id and signup_date columns.\n",
        "    web_df     : DataFrame with member_id and timestamp.\n",
        "    app_df     : DataFrame with member_id and timestamp.\n",
        "    claims_df  : DataFrame with member_id and diagnosis_date.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame indexed by member_id with columns:\n",
        "        days_since_last_web, days_since_last_app, days_since_last_claim,\n",
        "        days_since_last_activity, tenure_days, recent_any_7d.\n",
        "    \"\"\"\n",
        "    # Global reference date = max observed timestamp across all sources\n",
        "    ref_date = max(\n",
        "        pd.to_datetime(web_df[\"timestamp\"], errors=\"coerce\").dropna().max(),\n",
        "        pd.to_datetime(app_df[\"timestamp\"], errors=\"coerce\").dropna().max(),\n",
        "        pd.to_datetime(claims_df[\"diagnosis_date\"], errors=\"coerce\").dropna().max(),\n",
        "    )\n",
        "\n",
        "    # Per-member last timestamps (intermediates only)\n",
        "    last_web = web_df.groupby(\"member_id\")[\"timestamp\"].max()\n",
        "    last_app = app_df.groupby(\"member_id\")[\"timestamp\"].max()\n",
        "    last_claim = claims_df.groupby(\"member_id\")[\"diagnosis_date\"].max()\n",
        "\n",
        "    out = members_df[[\"member_id\", \"signup_date\"]].copy()\n",
        "\n",
        "    out[\"days_since_last_web\"] = out[\"member_id\"].map(last_web).pipe(lambda s: (ref_date - s).dt.days)\n",
        "    out[\"days_since_last_app\"] = out[\"member_id\"].map(last_app).pipe(lambda s: (ref_date - s).dt.days)\n",
        "    out[\"days_since_last_claim\"] = out[\"member_id\"].map(last_claim).pipe(lambda s: (ref_date - s).dt.days)\n",
        "\n",
        "    # Last activity across all three sources\n",
        "    last_any = (\n",
        "        pd.concat([last_web.rename(\"ts\"), last_app.rename(\"ts\"), last_claim.rename(\"ts\")])\n",
        "        .groupby(level=0).max()\n",
        "    )\n",
        "    out[\"days_since_last_activity\"] = out[\"member_id\"].map(last_any).pipe(lambda s: (ref_date - s).dt.days)\n",
        "\n",
        "    out[\"tenure_days\"] = (ref_date - pd.to_datetime(out[\"signup_date\"], errors=\"coerce\")).dt.days\n",
        "\n",
        "    out[\"recent_any_7d\"] = (out[\"days_since_last_activity\"].notna() & (out[\"days_since_last_activity\"] <= 7)).astype(int)\n",
        "\n",
        "    out = out.set_index(\"member_id\").drop(columns=[\"signup_date\"])\n",
        "    return out, ref_date\n",
        "\n",
        "\n",
        "recency = build_recency_tenure(churn_labels, web_visits, app_usage, claims)\n",
        "recency_df, ref_date = recency\n",
        "\n",
        "# Merge with labels for uplift computation\n",
        "rec = churn_labels[[\"member_id\", \"churn\", \"outreach\"]].merge(recency_df, left_on=\"member_id\", right_index=True)\n",
        "\n",
        "print(f\"Reference date: {ref_date}\")\n",
        "print(f\"Members: {len(rec)}\")\n",
        "print(rec[[\"days_since_last_web\", \"days_since_last_app\", \"days_since_last_claim\",\n",
        "           \"days_since_last_activity\", \"tenure_days\", \"recent_any_7d\"]].describe().round(1).to_string())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60ca6429",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9a – Uplift by days_since_last_web quartile\n",
        "\n",
        "feat = \"days_since_last_web\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "\n",
        "valid[\"_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"_bin\"].nunique() < 2:\n",
        "    valid[\"_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(valid[\"_bin\"].dropna().unique()):\n",
        "    ids = valid.loc[valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by days since last web activity\",\n",
        "                 xlabel=\"Days-since-last-web bin\")\n",
        "\n",
        "print(f\"Excluded from plot (no web activity): {excluded} members (n too small for stable uplift).\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672dcd42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9b – Uplift by days_since_last_app quartile\n",
        "\n",
        "feat = \"days_since_last_app\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "\n",
        "valid[\"_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"_bin\"].nunique() < 2:\n",
        "    valid[\"_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(valid[\"_bin\"].dropna().unique()):\n",
        "    ids = valid.loc[valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by days since last app activity\",\n",
        "                 xlabel=\"Days-since-last-app bin\")\n",
        "\n",
        "print(f\"Excluded from plot (no app activity): {excluded} members (n too small for stable uplift).\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad5a938",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9c – Uplift by days_since_last_claim quartile\n",
        "\n",
        "feat = \"days_since_last_claim\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "\n",
        "valid[\"_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"_bin\"].nunique() < 2:\n",
        "    valid[\"_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(valid[\"_bin\"].dropna().unique()):\n",
        "    ids = valid.loc[valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by days since last claim\",\n",
        "                 xlabel=\"Days-since-last-claim bin\")\n",
        "\n",
        "print(f\"Excluded from plot (no claims): {excluded} members (n too small for stable uplift).\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0ae7bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9d – Uplift by days_since_last_activity quartile\n",
        "\n",
        "feat = \"days_since_last_activity\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "\n",
        "valid[\"_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"_bin\"].nunique() < 2:\n",
        "    valid[\"_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(valid[\"_bin\"].dropna().unique()):\n",
        "    ids = valid.loc[valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by days since last activity (any source)\",\n",
        "                 xlabel=\"Days-since-last-activity bin\")\n",
        "\n",
        "print(f\"Excluded from plot (no activity at all): {excluded} members (n too small for stable uplift).\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b2965b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3.9e – Uplift by tenure_days quartile\n",
        "\n",
        "feat = \"tenure_days\"\n",
        "valid = rec.dropna(subset=[feat]).copy()\n",
        "excluded = len(rec) - len(valid)\n",
        "\n",
        "valid[\"_bin\"] = pd.qcut(valid[feat], q=4, duplicates=\"drop\")\n",
        "if valid[\"_bin\"].nunique() < 2:\n",
        "    valid[\"_bin\"] = pd.cut(valid[feat], bins=min(4, valid[feat].nunique()))\n",
        "\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(valid[\"_bin\"].dropna().unique()):\n",
        "    ids = valid.loc[valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by tenure (days since signup)\",\n",
        "                 xlabel=\"Tenure bin (days)\")\n",
        "\n",
        "print(f\"Excluded from plot (missing signup_date): {excluded} members (n too small for stable uplift).\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7202853",
      "metadata": {},
      "source": [
        "**What it means:** Uplift by recency and tenure bins shows how outreach effect varies with how recently members were active and how long they have been members.\n",
        "\n",
        "**What it says about further analysis:** Recency and tenure are strong candidates for the uplift model. EDA is complete; next steps are feature matrix construction and model training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58f09797",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **4. Feature Engineering Pipeline**\n",
        "\n",
        "A modular, reference-date-based pipeline that converts raw event tables into a member-level feature matrix.  \n",
        "The same functions work for **batch training** (with `ref_date = max activity in the data`) and **real-time scoring** (with `ref_date = scoring_date` or max in batch). **OBS_END** is used only to filter which events are loaded for train (Section 2), not as the feature reference date.\n",
        "\n",
        "### **4.1 Configuration and helpers**\n",
        "Constants, the WellCo brief loader, and a helper that derives `ref_date` from event tables to prevent cross-dataset leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca2769d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.1  Configuration and helpers ──────────────────────────────────────────\n",
        "\n",
        "# --- Pipeline constants (override these to reconfigure) ---------------------\n",
        "WELLCO_BRIEF_PATH: Path = FILE_DIR / \"wellco_client_brief.txt\"\n",
        "SIMILARITY_THRESHOLD: float = 0.2          # cosine-similarity cutoff for web relevance\n",
        "# Chosen based on the clear gap between irrelevant scores (max ≈ 0.13) and\n",
        "# relevant scores (min ≈ 0.26).  A threshold of 0.2 sits safely in that gap,\n",
        "# retaining all WellCo-related content while excluding unrelated visits.\n",
        "EMBED_MODEL_NAME: str = \"all-MiniLM-L6-v2\" # sentence-transformers model; swap as needed\n",
        "FOCUS_ICD_CODES: list[str] = [\"E11.9\", \"I10\", \"Z71.3\"]  # WellCo clinical focus codes\n",
        "\n",
        "\n",
        "def load_wellco_brief(path: Path | str = WELLCO_BRIEF_PATH) -> str:\n",
        "    \"\"\"Read the WellCo client brief from disk and return it as a single string.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : Path or str\n",
        "        File path to the brief text file (default: ``WELLCO_BRIEF_PATH``).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Full text content of the brief.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * The file exists and is UTF-8 encoded plain text.\n",
        "    * The text is used as the reference document for semantic-similarity\n",
        "      filtering of web visits (see 4.2).\n",
        "    \"\"\"\n",
        "    return Path(path).read_text(encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def ref_date_from_tables(*dfs: pd.DataFrame) -> pd.Timestamp:\n",
        "    \"\"\"Derive a per-dataset reference date from the latest timestamp in event tables.\n",
        "\n",
        "    This prevents cross-dataset leakage: train and test each compute their own\n",
        "    ``ref_date`` from their own event tables, rather than sharing a global constant.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    *dfs : pd.DataFrame\n",
        "        One or more event DataFrames.  Each must contain either a ``timestamp``\n",
        "        or a ``diagnosis_date`` column (or both).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.Timestamp\n",
        "        The maximum observed timestamp across all supplied tables.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * At least one DataFrame is provided.\n",
        "    * Date columns are already parsed as ``datetime64``.\n",
        "    \"\"\"\n",
        "    max_dates: list[pd.Timestamp] = []\n",
        "    for df in dfs:\n",
        "        if \"timestamp\" in df.columns:\n",
        "            max_dates.append(df[\"timestamp\"].max())\n",
        "        if \"diagnosis_date\" in df.columns:\n",
        "            max_dates.append(df[\"diagnosis_date\"].max())\n",
        "    if not max_dates:\n",
        "        raise ValueError(\"None of the supplied DataFrames contain 'timestamp' or 'diagnosis_date'.\")\n",
        "    return max(max_dates)\n",
        "\n",
        "\n",
        "def embed_wellco_brief(\n",
        "    brief_text: str,\n",
        "    model: SentenceTransformer,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Embed the WellCo client brief into a single vector.\n",
        "\n",
        "    Call this **once** at startup; reuse the returned embedding across all\n",
        "    datasets and scoring calls.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    brief_text : str\n",
        "        Full text of the WellCo client brief.\n",
        "    model : SentenceTransformer\n",
        "        Pre-loaded sentence-transformers model.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Shape ``(1, embedding_dim)`` — the brief's embedding vector.\n",
        "    \"\"\"\n",
        "    return model.encode([brief_text])\n",
        "\n",
        "\n",
        "def embed_visit_texts(\n",
        "    web_df: pd.DataFrame,\n",
        "    model: SentenceTransformer,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"Embed the concatenated title + description of each web visit.\n",
        "\n",
        "    **De-duplication optimisation:** Web-visit tables typically contain many\n",
        "    rows that share the same (title, description) pair — e.g. 100k+ rows\n",
        "    but only ~26 unique texts.  Rather than running the neural model on every\n",
        "    row, this function:\n",
        "\n",
        "    1. Builds one ``_text`` string per row:  ``(title + \" \" + description)``.\n",
        "    2. Uses ``pd.factorize`` to map each row to an integer index\n",
        "       (0, 1, 2, …) that identifies its *unique* text.\n",
        "       - ``codes``: array of length ``n_rows``; ``codes[i]`` = which unique\n",
        "         text row ``i`` belongs to.\n",
        "       - ``uniques``: array of length ``n_unique``; the actual unique strings.\n",
        "    3. Embeds only the ``n_unique`` texts with the model (e.g. 26 instead\n",
        "       of 100k+).\n",
        "    4. Uses NumPy array indexing (``unique_embeddings[codes]``) to expand\n",
        "       back to one embedding per row — no Python loop, one vectorised step.\n",
        "\n",
        "    The result is identical to embedding every row individually, but orders\n",
        "    of magnitude faster when duplicates dominate.\n",
        "\n",
        "    Reusable for both batch processing and real-time scoring of individual\n",
        "    or small batches of visits.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    web_df : pd.DataFrame\n",
        "        Must contain ``title`` and ``description`` columns (NaN allowed).\n",
        "    model : SentenceTransformer\n",
        "        Pre-loaded sentence-transformers model (same one used for the brief).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Shape ``(len(web_df), embedding_dim)`` — one embedding per visit.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``title`` and ``description`` may be NaN; they are filled with \"\".\n",
        "    * The caller is responsible for any time-filtering before calling this.\n",
        "    \"\"\"\n",
        "    # 1. Build one text string per row\n",
        "    texts = (\n",
        "        web_df[\"title\"].fillna(\"\") + \" \" + web_df[\"description\"].fillna(\"\")\n",
        "    ).str.strip()\n",
        "\n",
        "    # 2. Factorize: assign each row an integer id pointing to its unique text\n",
        "    #    codes  – shape (n_rows,)   : codes[i] = index of row i's unique text\n",
        "    #    uniques – shape (n_unique,) : the actual unique strings\n",
        "    codes, uniques = pd.factorize(texts)\n",
        "\n",
        "    # 3. Embed only the unique texts (e.g. 26 instead of 100k+)\n",
        "    unique_embeddings = model.encode(uniques.tolist())  # shape (n_unique, dim)\n",
        "\n",
        "    print(\n",
        "        f\"  embed_visit_texts: {len(uniques):,} unique texts embedded \"\n",
        "        f\"(from {len(texts):,} rows)\"\n",
        "    )\n",
        "\n",
        "    # 4. Map back: one array-indexing step gives every row its embedding\n",
        "    #    visit_embeddings[i] = unique_embeddings[codes[i]]\n",
        "    return unique_embeddings[codes]\n",
        "\n",
        "\n",
        "print(f\"Similarity threshold – {SIMILARITY_THRESHOLD}\")\n",
        "print(f\"Embedding model      – {EMBED_MODEL_NAME}\")\n",
        "print(f\"Focus ICD codes      – {FOCUS_ICD_CODES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c77f1f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── RUN ONCE: load embedding model & embed WellCo brief ────────────────────\n",
        "# This cell is intentionally isolated so it runs exactly once per session.\n",
        "# All downstream cells reuse `embed_model` and `wellco_embedding`.\n",
        "\n",
        "brief_text = load_wellco_brief()\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "wellco_embedding = embed_wellco_brief(brief_text, embed_model)  # shape (1, dim)\n",
        "\n",
        "print(f\"WellCo brief loaded     – {len(brief_text):,} characters\")\n",
        "print(f\"Embedding model loaded  – {EMBED_MODEL_NAME}\")\n",
        "print(f\"WellCo embedding shape  – {wellco_embedding.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9d6a5d",
      "metadata": {},
      "source": [
        "### **4.2 Web relevance filtering (embeddings)**\n",
        "Using the pre-computed `wellco_embedding` and `embed_model` (loaded once in the cell above), embed each web-visit's text and retain only visits whose cosine similarity exceeds the configurable threshold. **Embeddings are used solely for relevance filtering and are never fed into the model as features.**\n",
        "\n",
        "**Performance optimisation:** `embed_visit_texts` uses `pd.factorize` to identify unique (title, description) pairs and embeds only those (e.g. ~26 unique texts instead of 100k+ rows). Embeddings are then mapped back to all rows via a single NumPy array-indexing step, making the process orders of magnitude faster when duplicates dominate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4202845d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.2  Web relevance filtering ────────────────────────────────────────────\n",
        "\n",
        "def filter_wellco_relevant_visits(\n",
        "    web_df: pd.DataFrame,\n",
        "    wellco_embedding: np.ndarray,\n",
        "    embed_model: SentenceTransformer,\n",
        "    similarity_threshold: float = SIMILARITY_THRESHOLD,\n",
        "    ref_date: pd.Timestamp | None = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Return only web visits that are semantically relevant to the WellCo brief.\n",
        "\n",
        "    The WellCo brief embedding and the embedding model are created once\n",
        "    (in the \"RUN ONCE\" cell) and passed in here — no redundant loading.\n",
        "\n",
        "    ``embed_visit_texts`` internally de-duplicates texts via ``pd.factorize``\n",
        "    so the neural model only runs on the *unique* (title, description) pairs\n",
        "    (e.g. ~26) rather than every row (e.g. 100k+), then maps embeddings back\n",
        "    to all rows with one NumPy array-indexing step.\n",
        "\n",
        "    Steps\n",
        "    -----\n",
        "    1. (Optional) Filter to ``timestamp <= ref_date`` if a ref_date is supplied.\n",
        "    2. Embed visit texts via ``embed_visit_texts`` (title + description,\n",
        "       with internal de-duplication for speed).\n",
        "    3. Compute cosine similarity of each visit embedding to ``wellco_embedding``.\n",
        "    4. Keep rows where similarity >= ``similarity_threshold``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    web_df : pd.DataFrame\n",
        "        Raw web-visits table with columns ``member_id``, ``timestamp``,\n",
        "        ``title``, ``description``, ``url``.\n",
        "    wellco_embedding : np.ndarray\n",
        "        Pre-computed embedding of the WellCo brief, shape ``(1, dim)``.\n",
        "    embed_model : SentenceTransformer\n",
        "        Pre-loaded sentence-transformers model (same one used to create\n",
        "        ``wellco_embedding``).\n",
        "    similarity_threshold : float\n",
        "        Minimum cosine similarity to retain a visit (default from config).\n",
        "    ref_date : pd.Timestamp or None\n",
        "        If provided, only visits with ``timestamp <= ref_date`` are considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Subset of ``web_df`` (same schema) containing only WellCo-relevant visits.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``title`` and ``description`` may contain NaN; they are filled with \"\".\n",
        "    * Embeddings are used *only* for filtering — no embedding dimensions are\n",
        "      added to the downstream feature matrix.\n",
        "    \"\"\"\n",
        "    df = web_df.copy()\n",
        "\n",
        "    # 1. Time filter\n",
        "    if ref_date is not None:\n",
        "        df = df[df[\"timestamp\"] <= ref_date]\n",
        "\n",
        "    if df.empty:\n",
        "        return df\n",
        "\n",
        "    # 2. Embed visit texts\n",
        "    visit_embeddings = embed_visit_texts(df, embed_model)  # shape (n, dim)\n",
        "\n",
        "    # 3. Cosine similarity → 1-D array\n",
        "    similarities = cosine_similarity(visit_embeddings, wellco_embedding).flatten()\n",
        "\n",
        "    # 4. Filter\n",
        "    mask = similarities >= similarity_threshold\n",
        "    relevant = df[mask].copy()\n",
        "\n",
        "    print(\n",
        "        f\"Web relevance filter: {mask.sum():,} / {len(mask):,} visits retained \"\n",
        "        f\"(threshold={similarity_threshold})\"\n",
        "    )\n",
        "    return relevant"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc811ac3",
      "metadata": {},
      "source": [
        "### **4.3 Per-source aggregation functions**\n",
        "Each function takes the relevant event DataFrame(s) and an explicit `ref_date`, filters events to `<= ref_date`, and returns a **member-level** DataFrame keyed by `member_id`.\n",
        "\n",
        "| Source | Features produced |\n",
        "|---|---|\n",
        "| Web (relevant visits) | `wellco_web_visits_count`, `days_since_last_wellco_web` |\n",
        "| App | `app_sessions_count` |\n",
        "| Claims | `icd_distinct_count`, `has_focus_icd`, `days_since_last_claim` |\n",
        "| Lifecycle | `tenure_days` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74e38a32",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.3a  Web aggregation ───────────────────────────────────────────────────\n",
        "\n",
        "def agg_web_features(\n",
        "    web_relevant_df: pd.DataFrame,\n",
        "    members_df: pd.DataFrame,\n",
        "    ref_date: pd.Timestamp,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Aggregate WellCo-relevant web visits into member-level features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    web_relevant_df : pd.DataFrame\n",
        "        Output of ``filter_wellco_relevant_visits`` — already filtered by\n",
        "        relevance *and* ``timestamp <= ref_date``.\n",
        "    members_df : pd.DataFrame\n",
        "        Member roster (must contain ``member_id``); used as the left table so\n",
        "        every member gets a row even if they have zero relevant visits.\n",
        "    ref_date : pd.Timestamp\n",
        "        Decision / reference date for computing recency.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns: ``member_id``, ``wellco_web_visits_count``,\n",
        "        ``wellco_web_unique_urls``, ``days_since_last_wellco_web``.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``web_relevant_df`` has columns ``member_id``, ``timestamp``, ``url``.\n",
        "    * Members with no relevant visits get count = 0, unique_urls = 0, and\n",
        "      ``days_since_last_wellco_web = NaN`` (no visit to measure from).\n",
        "    \"\"\"\n",
        "    # Redundant safety filter (already done in filter step)\n",
        "    wdf = web_relevant_df[web_relevant_df[\"timestamp\"] <= ref_date].copy()\n",
        "\n",
        "    if wdf.empty:\n",
        "        out = members_df[[\"member_id\"]].copy()\n",
        "        out[\"wellco_web_visits_count\"] = 0\n",
        "        # TOGGLE: uncomment next line to include URL feature in the matrix\n",
        "        # out[\"wellco_web_unique_urls\"] = 0\n",
        "        out[\"days_since_last_wellco_web\"] = np.nan\n",
        "        return out\n",
        "\n",
        "    agg = (\n",
        "        wdf.groupby(\"member_id\")\n",
        "        .agg(\n",
        "            wellco_web_visits_count=(\"timestamp\", \"count\"),\n",
        "            # TOGGLE: uncomment next line to include URL feature in the matrix\n",
        "            # wellco_web_unique_urls=(\"url\", \"nunique\"),\n",
        "            _last_visit=(\"timestamp\", \"max\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    agg[\"days_since_last_wellco_web\"] = (ref_date - agg[\"_last_visit\"]).dt.days\n",
        "    agg.drop(columns=\"_last_visit\", inplace=True)\n",
        "\n",
        "    # Left join so every member gets a row\n",
        "    out = members_df[[\"member_id\"]].merge(agg, on=\"member_id\", how=\"left\")\n",
        "    out[\"wellco_web_visits_count\"] = out[\"wellco_web_visits_count\"].fillna(0).astype(int)\n",
        "    # TOGGLE: uncomment next line to include URL feature in the matrix\n",
        "    # out[\"wellco_web_unique_urls\"] = out[\"wellco_web_unique_urls\"].fillna(0).astype(int)\n",
        "    # days_since_last_wellco_web stays NaN for members with no relevant visits\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c1945a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.3b  App aggregation ───────────────────────────────────────────────────\n",
        "\n",
        "def agg_app_features(\n",
        "    app_df: pd.DataFrame,\n",
        "    members_df: pd.DataFrame,\n",
        "    ref_date: pd.Timestamp,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Count app sessions per member up to the reference date.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    app_df : pd.DataFrame\n",
        "        Raw app-usage table with columns ``member_id``, ``timestamp``.\n",
        "    members_df : pd.DataFrame\n",
        "        Member roster (must contain ``member_id``).\n",
        "    ref_date : pd.Timestamp\n",
        "        Decision / reference date; only sessions with ``timestamp <= ref_date``\n",
        "        are counted.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns: ``member_id``, ``app_sessions_count``.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * Each row in ``app_df`` represents one session.\n",
        "    * Members with no sessions get ``app_sessions_count = 0``.\n",
        "    \"\"\"\n",
        "    adf = app_df[app_df[\"timestamp\"] <= ref_date].copy()\n",
        "\n",
        "    counts = (\n",
        "        adf.groupby(\"member_id\")\n",
        "        .size()\n",
        "        .rename(\"app_sessions_count\")\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    out = members_df[[\"member_id\"]].merge(counts, on=\"member_id\", how=\"left\")\n",
        "    out[\"app_sessions_count\"] = out[\"app_sessions_count\"].fillna(0).astype(int)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13498c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.3c  Claims aggregation ────────────────────────────────────────────────\n",
        "\n",
        "def agg_claims_features(\n",
        "    claims_df: pd.DataFrame,\n",
        "    members_df: pd.DataFrame,\n",
        "    ref_date: pd.Timestamp,\n",
        "    focus_icd_codes: list[str] = FOCUS_ICD_CODES,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Aggregate claims into member-level diagnostic features.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    claims_df : pd.DataFrame\n",
        "        Raw claims table with columns ``member_id``, ``diagnosis_date``,\n",
        "        ``icd_code``.\n",
        "    members_df : pd.DataFrame\n",
        "        Member roster (must contain ``member_id``).\n",
        "    ref_date : pd.Timestamp\n",
        "        Decision / reference date; only claims with\n",
        "        ``diagnosis_date <= ref_date`` are included.\n",
        "    focus_icd_codes : list[str]\n",
        "        ICD-10 codes that define the WellCo clinical focus (default from config).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns: ``member_id``, ``icd_distinct_count``, ``has_focus_icd``,\n",
        "        ``days_since_last_claim``.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``icd_code`` is a string column.\n",
        "    * ``has_focus_icd`` is binary (1 if the member has >= 1 claim with a focus\n",
        "      ICD code, else 0).\n",
        "    * Members with no claims get counts = 0, ``has_focus_icd = 0``, and\n",
        "      ``days_since_last_claim = NaN``.\n",
        "    \"\"\"\n",
        "    cdf = claims_df[claims_df[\"diagnosis_date\"] <= ref_date].copy()\n",
        "\n",
        "    if cdf.empty:\n",
        "        out = members_df[[\"member_id\"]].copy()\n",
        "        out[\"icd_distinct_count\"] = 0\n",
        "        out[\"has_focus_icd\"] = 0\n",
        "        out[\"days_since_last_claim\"] = np.nan\n",
        "        return out\n",
        "\n",
        "    # Flag focus ICD rows\n",
        "    cdf[\"_is_focus\"] = cdf[\"icd_code\"].isin(focus_icd_codes)\n",
        "\n",
        "    agg = (\n",
        "        cdf.groupby(\"member_id\")\n",
        "        .agg(\n",
        "            icd_distinct_count=(\"icd_code\", \"nunique\"),\n",
        "            has_focus_icd=(\"_is_focus\", \"any\"),\n",
        "            _last_claim=(\"diagnosis_date\", \"max\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    agg[\"has_focus_icd\"] = agg[\"has_focus_icd\"].astype(int)\n",
        "    agg[\"days_since_last_claim\"] = (ref_date - agg[\"_last_claim\"]).dt.days\n",
        "    agg.drop(columns=\"_last_claim\", inplace=True)\n",
        "\n",
        "    out = members_df[[\"member_id\"]].merge(agg, on=\"member_id\", how=\"left\")\n",
        "    out[\"icd_distinct_count\"] = out[\"icd_distinct_count\"].fillna(0).astype(int)\n",
        "    out[\"has_focus_icd\"] = out[\"has_focus_icd\"].fillna(0).astype(int)\n",
        "    # days_since_last_claim stays NaN for members with no claims\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd230cae",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.3d  Lifecycle / tenure ────────────────────────────────────────────────\n",
        "\n",
        "def agg_lifecycle_tenure(\n",
        "    members_df: pd.DataFrame,\n",
        "    ref_date: pd.Timestamp,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Compute membership tenure in days as of the reference date.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    members_df : pd.DataFrame\n",
        "        Member roster with columns ``member_id`` and ``signup_date``.\n",
        "    ref_date : pd.Timestamp\n",
        "        Decision / reference date.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Columns: ``member_id``, ``tenure_days``.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``signup_date`` is already parsed as ``datetime64``.\n",
        "    * If ``signup_date`` is NaT the resulting ``tenure_days`` will be NaN.\n",
        "    \"\"\"\n",
        "    out = members_df[[\"member_id\"]].copy()\n",
        "    out[\"tenure_days\"] = (ref_date - members_df[\"signup_date\"]).dt.days\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48bf5553",
      "metadata": {},
      "source": [
        "### **4.4 Feature assembly**\n",
        "`build_feature_matrix` orchestrates the full pipeline: relevance filtering, all four aggregations, and a single merge into one member-level table. Pass `include_labels=True` to attach `outreach` and `churn` columns for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81298605",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.4  Feature assembly ───────────────────────────────────────────────────\n",
        "\n",
        "def build_feature_matrix(\n",
        "    members_df: pd.DataFrame,\n",
        "    web_df: pd.DataFrame,\n",
        "    app_df: pd.DataFrame,\n",
        "    claims_df: pd.DataFrame,\n",
        "    ref_date: pd.Timestamp,\n",
        "    *,\n",
        "    wellco_embedding: np.ndarray,\n",
        "    embed_model: SentenceTransformer,\n",
        "    similarity_threshold: float = SIMILARITY_THRESHOLD,\n",
        "    focus_icd_codes: list[str] = FOCUS_ICD_CODES,\n",
        "    include_labels: bool = False,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Build the full member-level feature matrix from raw event tables.\n",
        "\n",
        "    This is the single entry-point for both batch training and real-time\n",
        "    scoring.  It calls the relevance filter and all four aggregation functions,\n",
        "    then merges everything on ``member_id``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    members_df : pd.DataFrame\n",
        "        Member roster.  Must contain ``member_id`` and ``signup_date``.\n",
        "        For training data this is ``churn_labels`` (which also has ``outreach``\n",
        "        and ``churn``).\n",
        "    web_df, app_df, claims_df : pd.DataFrame\n",
        "        Raw event tables (web visits, app sessions, claims).\n",
        "    ref_date : pd.Timestamp\n",
        "        Decision / reference date.  All event filters use ``<= ref_date``.\n",
        "    wellco_embedding : np.ndarray\n",
        "        Pre-computed WellCo brief embedding, shape ``(1, dim)``.\n",
        "        Created once in the \"RUN ONCE\" cell.\n",
        "    embed_model : SentenceTransformer\n",
        "        Pre-loaded sentence-transformers model (same one used to create\n",
        "        ``wellco_embedding``).\n",
        "    similarity_threshold : float\n",
        "        Cosine-similarity cutoff for web relevance (default from config).\n",
        "    focus_icd_codes : list[str]\n",
        "        ICD-10 focus codes (default from config).\n",
        "    include_labels : bool\n",
        "        If True and ``members_df`` contains ``outreach`` / ``churn``, append\n",
        "        those columns to the output (for training only).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        One row per member.  Feature columns: ``wellco_web_visits_count``,\n",
        "        ``days_since_last_wellco_web``, ``app_sessions_count``,\n",
        "        ``icd_distinct_count``, ``has_focus_icd``, ``days_since_last_claim``,\n",
        "        ``tenure_days`` (7 features).\n",
        "        Optionally ``outreach`` and ``churn`` if ``include_labels=True``.\n",
        "\n",
        "    Assumptions\n",
        "    -----------\n",
        "    * ``members_df`` is the source of truth for the member list.\n",
        "    * Event tables may have extra members (ignored) or fewer (filled with\n",
        "      0 / NaN as documented in each aggregation function).\n",
        "    \"\"\"\n",
        "    # 1. Relevance filter on web visits\n",
        "    web_relevant = filter_wellco_relevant_visits(\n",
        "        web_df,\n",
        "        wellco_embedding=wellco_embedding,\n",
        "        embed_model=embed_model,\n",
        "        similarity_threshold=similarity_threshold,\n",
        "        ref_date=ref_date,\n",
        "    )\n",
        "\n",
        "    # 2. Per-source aggregations\n",
        "    feat_web = agg_web_features(web_relevant, members_df, ref_date)\n",
        "    feat_app = agg_app_features(app_df, members_df, ref_date)\n",
        "    feat_claims = agg_claims_features(claims_df, members_df, ref_date, focus_icd_codes)\n",
        "    feat_life = agg_lifecycle_tenure(members_df, ref_date)\n",
        "\n",
        "    # 3. Merge all on member_id (left from members so every member has a row)\n",
        "    feature_matrix = (\n",
        "        members_df[[\"member_id\"]]\n",
        "        .merge(feat_web, on=\"member_id\", how=\"left\")\n",
        "        .merge(feat_app, on=\"member_id\", how=\"left\")\n",
        "        .merge(feat_claims, on=\"member_id\", how=\"left\")\n",
        "        .merge(feat_life, on=\"member_id\", how=\"left\")\n",
        "    )\n",
        "\n",
        "    # 4. Attach labels if requested\n",
        "    if include_labels:\n",
        "        label_cols = [c for c in (\"outreach\", \"churn\") if c in members_df.columns]\n",
        "        if label_cols:\n",
        "            feature_matrix = feature_matrix.merge(\n",
        "                members_df[[\"member_id\"] + label_cols], on=\"member_id\", how=\"left\"\n",
        "            )\n",
        "\n",
        "    return feature_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fe08b5f",
      "metadata": {},
      "source": [
        "### **4.5 Build train and test feature matrices**\n",
        "**Train events** are filtered to those that occurred **until OBS_END** (Section 2: `web_visits`, `app_usage`, `claims` use `timestamp` / `diagnosis_date` < OBS_END). So the train feature matrix is built from events up to that date only.\n",
        "\n",
        "**Ref date:** For both train and test, `ref_date` is the **max timestamp** in that dataset's event tables (`ref_date_from_tables(...)`), so features are \"as of\" the latest activity in the data. This keeps the pipeline reproducible at any future decision time. OBS_END is not passed as the feature reference date; it only defines which events are included in the train tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "765fe65e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.5  Build train & test feature matrices ────────────────────────────────\n",
        "\n",
        "# --- Reference dates: max activity in each dataset (reproducible at any decision time) ---\n",
        "# Train tables (web_visits, app_usage, claims) contain only events that occurred until OBS_END (filtered in Section 2).\n",
        "# ref_date is the max timestamp in those tables, not OBS_END itself.\n",
        "ref_date_train = ref_date_from_tables(web_visits, app_usage, claims)\n",
        "ref_date_test = ref_date_from_tables(test_web_visits, test_app_usage, test_claims)\n",
        "\n",
        "print(f\"ref_date_train = {ref_date_train}  (max activity in train tables)\")\n",
        "print(f\"ref_date_test  = {ref_date_test}  (max activity in test tables)\")\n",
        "\n",
        "# --- Train ------------------------------------------------------------------\n",
        "print(\"\\n── Building TRAIN feature matrix ──\")\n",
        "train_features = build_feature_matrix(\n",
        "    members_df=churn_labels,\n",
        "    web_df=web_visits,\n",
        "    app_df=app_usage,\n",
        "    claims_df=claims,\n",
        "    ref_date=ref_date_train,\n",
        "    wellco_embedding=wellco_embedding,\n",
        "    embed_model=embed_model,\n",
        "    include_labels=True,\n",
        ")\n",
        "\n",
        "# --- Test -------------------------------------------------------------------\n",
        "print(\"\\n── Building TEST feature matrix ──\")\n",
        "test_features = build_feature_matrix(\n",
        "    members_df=test_members,\n",
        "    web_df=test_web_visits,\n",
        "    app_df=test_app_usage,\n",
        "    claims_df=test_claims,\n",
        "    ref_date=ref_date_test,\n",
        "    wellco_embedding=wellco_embedding,\n",
        "    embed_model=embed_model,\n",
        "    include_labels=False,\n",
        ")\n",
        "\n",
        "# --- Quick summary ----------------------------------------------------------\n",
        "print(f\"\\nTrain features shape: {train_features.shape}\")\n",
        "print(f\"Test  features shape: {test_features.shape}\")\n",
        "print(f\"\\nTrain columns: {list(train_features.columns)}\")\n",
        "print(f\"Test  columns: {list(test_features.columns)}\")\n",
        "print(f\"\\nTrain head:\\n{train_features.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caf81e00",
      "metadata": {},
      "source": [
        "### **4.6 Feature diagnostics (informational only)**\n",
        "Inspect distributions and multicollinearity of the engineered features **on the training set**. This section is for review only — no features are automatically dropped or transformed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d5f8fed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6a  Per-feature distribution diagnostics ──────────────────────────────\n",
        "\n",
        "# Feature columns only (exclude member_id and labels)\n",
        "FEATURE_COLS = [\n",
        "    \"wellco_web_visits_count\",\n",
        "    # TOGGLE: uncomment next line to include URL feature in diagnostics\n",
        "    # \"wellco_web_unique_urls\",\n",
        "    \"days_since_last_wellco_web\",\n",
        "    \"app_sessions_count\",\n",
        "    \"icd_distinct_count\",\n",
        "    \"has_focus_icd\",\n",
        "    \"days_since_last_claim\",\n",
        "    \"tenure_days\",\n",
        "]\n",
        "\n",
        "# Summary statistics\n",
        "print(\"=\" * 70)\n",
        "print(\"FEATURE SUMMARY STATISTICS (train)\")\n",
        "print(\"=\" * 70)\n",
        "print(train_features[FEATURE_COLS].describe().T.to_string())\n",
        "\n",
        "# Percentage of zeros and missing\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ZEROS AND MISSING VALUES (train)\")\n",
        "print(\"=\" * 70)\n",
        "n = len(train_features)\n",
        "for col in FEATURE_COLS:\n",
        "    pct_zero = (train_features[col] == 0).sum() / n * 100\n",
        "    pct_miss = train_features[col].isna().sum() / n * 100\n",
        "    print(f\"  {col:<35s}  zeros: {pct_zero:6.2f}%   missing: {pct_miss:6.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6ea6c09",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6b  Histograms ────────────────────────────────────────────────────────\n",
        "# Each plot: x = feature value (e.g. number of visits), y = how many members have that value.\n",
        "FEATURE_XLABELS = {\n",
        "    \"wellco_web_visits_count\": \"Relevant web visits per member\",\n",
        "    \"wellco_web_unique_urls\": \"Unique URLs (WellCo-relevant visits)\",\n",
        "    \"days_since_last_wellco_web\": \"Days since last relevant web visit\",\n",
        "    \"app_sessions_count\": \"App sessions per member\",\n",
        "    \"icd_distinct_count\": \"Distinct ICD codes per member\",\n",
        "    \"has_focus_icd\": \"Has focus ICD (0 = no, 1 = yes)\",\n",
        "    \"days_since_last_claim\": \"Days since last claim\",\n",
        "    \"tenure_days\": \"Tenure (days since signup)\",\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(FEATURE_COLS):\n",
        "    ax = axes[i]\n",
        "    data = train_features[col].dropna()\n",
        "    ax.hist(data, bins=40, edgecolor=\"white\", alpha=0.8)\n",
        "    ax.set_title(col, fontsize=10, fontweight=\"bold\")\n",
        "    ax.set_xlabel(FEATURE_XLABELS.get(col, col), fontsize=10)\n",
        "    ax.set_ylabel(\"Number of members\", fontsize=10)\n",
        "    # Annotate with basic stats\n",
        "    ax.axvline(data.median(), color=\"red\", linestyle=\"--\", linewidth=1, label=f\"median={data.median():.1f}\")\n",
        "    ax.legend(fontsize=7)\n",
        "    set_axes_clear(ax, x_axis_at_zero=False)\n",
        "\n",
        "# TOGGLE: comment next line when URL is in FEATURE_COLS (8 features fill the 2x4 grid)\n",
        "axes[7].set_visible(False)  # 7 features → hide empty 8th subplot\n",
        "\n",
        "plt.suptitle(\"Feature distributions: how many members have each value (train set)\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f78edaa4",
      "metadata": {},
      "source": [
        "**What we see in these distribution plots (train set):** Each histogram shows how many members have each value for one feature. **wellco_web_visits_count:** Strong right skew; most members in the 0–5 or 5–14 range, long tail up to 62 visits — a few heavy engagers. **wellco_web_unique_urls:** Almost identical shape to visit count (same data, one row per URL), so redundant; we drop it from the matrix. **days_since_last_wellco_web:** Right-skewed; many at 0–1 days, tail out to 13; ~2% missing (no relevant visit). **app_sessions_count:** More symmetric, roughly bell-shaped; median ~10, less skew than web/claims. **icd_distinct_count:** Multi-modal (several peaks at 4, 5, 6 codes). **has_focus_icd:** Almost all 1 (92%+); near-binary. **days_since_last_claim:** Right-skewed; peak at 1–2 days. **tenure_days:** Right-skewed; spread from 45 to 561 days. For tree-based uplift models we use these as-is; for linear models we'd log1p skewed counts and keep binary 0/1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3562a0fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6c  Multicollinearity diagnostic ──────────────────────────────────────\n",
        "\n",
        "corr = train_features[FEATURE_COLS].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"coolwarm\",\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    square=True,\n",
        "    linewidths=0.5,\n",
        ")\n",
        "plt.title(\"Feature Correlation Matrix (train set)\", fontsize=14, fontweight=\"bold\")\n",
        "plt.xlabel(\"Feature\", fontsize=12)\n",
        "plt.ylabel(\"Feature\", fontsize=12)\n",
        "set_axes_clear(plt.gca(), x_axis_at_zero=False)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Flag highly correlated pairs (|r| >= 0.8)\n",
        "HIGH_CORR_THRESHOLD = 0.8\n",
        "print(f\"\\nPairs with |correlation| >= {HIGH_CORR_THRESHOLD}:\")\n",
        "flagged = []\n",
        "for i in range(len(FEATURE_COLS)):\n",
        "    for j in range(i + 1, len(FEATURE_COLS)):\n",
        "        r = corr.iloc[i, j]\n",
        "        if abs(r) >= HIGH_CORR_THRESHOLD:\n",
        "            flagged.append((FEATURE_COLS[i], FEATURE_COLS[j], r))\n",
        "            print(f\"  {FEATURE_COLS[i]}  ↔  {FEATURE_COLS[j]}  :  r = {r:.3f}\")\n",
        "if not flagged:\n",
        "    print(\"  (none)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2578074f",
      "metadata": {},
      "source": [
        "**What we see in this heatmap:** The plot above is the correlation matrix of the 8 feature columns (including `wellco_web_unique_urls`). The only pair with |r| ≥ 0.8 is **wellco_web_visits_count** and **wellco_web_unique_urls** — they are **perfectly correlated** (r = 1.0). That is because both were computed from the same WellCo-relevant rows: in that subset each visit is one row and one URL, so the two counts are identical. All other pairs in this matrix are moderate or weak (e.g. tenure vs. recency, app vs. web); no other near-perfect correlation appears. **Decision:** We drop `wellco_web_unique_urls` from the feature matrix for modeling (7 features) to avoid multicollinearity; the diagnostics above still show the 8-feature version so it is clear we tried the URL feature and why we dropped it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eea732e",
      "metadata": {},
      "source": [
        "#### **4.6d Uplift by WellCo-relevant web features**\n",
        "In the EDA (Section 3.7) we checked uplift by **raw** web activity (all visits). Now that the pipeline filters visits to only WellCo-relevant content, we verify that **these filtered features** carry uplift signal. We plot uplift by **three** web-related quantities: `wellco_web_visits_count`, `wellco_web_unique_urls` (included here for diagnostics only; we tried it but removed it from the feature matrix — see 4.6c), and `days_since_last_wellco_web`. Plot outputs below were generated when the matrix still had the URL column; the feature matrix used for modeling now has 7 features (no URL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e2eb7b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.6d  Uplift by WellCo-relevant web features ───────────────────────────\n",
        "# Uses the existing `compute_uplift` and `plot_uplift_bars` from Section 3.6,\n",
        "# and the `labels` DataFrame (= churn_labels[[\"member_id\",\"churn\",\"outreach\"]]).\n",
        "# `train_features` already contains the three web features plus outreach/churn.\n",
        "\n",
        "# Helper: merge train_features with labels so compute_uplift can look up IDs\n",
        "_web_uplift_df = train_features[[\"member_id\",\n",
        "                                  \"wellco_web_visits_count\",\n",
        "                                  \"wellco_web_unique_urls\",\n",
        "                                  \"days_since_last_wellco_web\"]].copy()\n",
        "\n",
        "# ── 1. Uplift by wellco_web_visits_count (quartiles) ───────────────────────\n",
        "_web_uplift_df[\"_bin\"] = pd.qcut(\n",
        "    _web_uplift_df[\"wellco_web_visits_count\"], q=4, duplicates=\"drop\"\n",
        ")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(_web_uplift_df[\"_bin\"].dropna().unique()):\n",
        "    ids = _web_uplift_df.loc[_web_uplift_df[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by WellCo-relevant web visits (count)\",\n",
        "                 xlabel=\"wellco_web_visits_count (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n",
        "\n",
        "# ── 2. Uplift by wellco_web_unique_urls (quartiles) ────────────────────────\n",
        "_web_uplift_df[\"_bin\"] = pd.qcut(\n",
        "    _web_uplift_df[\"wellco_web_unique_urls\"], q=4, duplicates=\"drop\"\n",
        ")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(_web_uplift_df[\"_bin\"].dropna().unique()):\n",
        "    ids = _web_uplift_df.loc[_web_uplift_df[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by WellCo-relevant unique URLs\",\n",
        "                 xlabel=\"wellco_web_unique_urls (quartile)\")\n",
        "\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")\n",
        "\n",
        "# ── 3. Uplift by days_since_last_wellco_web (quartiles) ────────────────────\n",
        "# Members with NaN (no relevant visits at all) are excluded from binning\n",
        "# but reported separately.\n",
        "_valid = _web_uplift_df.dropna(subset=[\"days_since_last_wellco_web\"])\n",
        "_excluded = len(_web_uplift_df) - len(_valid)\n",
        "_valid = _valid.copy()\n",
        "_valid[\"_bin\"] = pd.qcut(\n",
        "    _valid[\"days_since_last_wellco_web\"], q=4, duplicates=\"drop\"\n",
        ")\n",
        "bin_names, uplifts, nts, ncs = [], [], [], []\n",
        "for b in sorted(_valid[\"_bin\"].dropna().unique()):\n",
        "    ids = _valid.loc[_valid[\"_bin\"] == b, \"member_id\"]\n",
        "    u, nt, nc = compute_uplift(ids)\n",
        "    bin_names.append(str(b)); uplifts.append(u); nts.append(nt); ncs.append(nc)\n",
        "\n",
        "plot_uplift_bars(bin_names, uplifts,\n",
        "                 title=\"Uplift by days since last WellCo-relevant web visit\",\n",
        "                 xlabel=\"days_since_last_wellco_web (quartile)\")\n",
        "\n",
        "print(f\"Excluded from plot (no relevant web visits): {_excluded} members.\")\n",
        "print(f\"{'Bin':<25} {'Uplift':>8} {'n_treated':>10} {'n_control':>10}\")\n",
        "for name, u, nt, nc in zip(bin_names, uplifts, nts, ncs):\n",
        "    print(f\"{name:<25} {u:>8.4f} {nt:>10} {nc:>10}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f6122b",
      "metadata": {},
      "source": [
        "**What we see in these uplift plots:** Each bar chart bins members by quartiles of one WellCo-relevant web feature and shows the **uplift** (churn rate difference: control − treated) in that bin. **Plot 1 (wellco_web_visits_count):** Uplift is small and slightly negative across quartiles; more visits do not show a clearly stronger or weaker outreach effect here. **Plot 2 (wellco_web_unique_urls):** Mirrors the visit-count plot (same redundancy as in the correlation heatmap); we kept this plot to show we tried the URL feature. **Plot 3 (days_since_last_wellco_web):** Members with no relevant visit are excluded; across quartiles uplift is again modest. Overall, these filtered web features show some variation in uplift by segment but no single strong moderator; they remain useful as inputs to the uplift model rather than as standalone targeting rules."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5279867b",
      "metadata": {},
      "source": [
        "### **4.7 Relevance filter sanity test**\n",
        "The 26 unique (title, description) pairs in the web data split into two groups based on the WellCo brief (nutrition, exercise, sleep, stress, diabetes, hypertension, cardiometabolic health). This test uses a **new fixture** (different members 10–12 and a different mix of titles) so you can verify that the current `SIMILARITY_THRESHOLD` generalizes — expected counts are from ground truth (`WELLCO_RELEVANT_TITLES` / `NOT_RELEVANT_TITLES`). If the test passes, the threshold is separating relevant from non-relevant correctly on these unseen examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904912c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 4.7  Relevance filter sanity test ───────────────────────────────────────\n",
        "#\n",
        "# Ground-truth grouping of the 26 unique (title, description) pairs in the\n",
        "# web-visits data, classified by whether the content aligns with the WellCo\n",
        "# brief (nutrition, exercise, sleep, stress, diabetes, hypertension,\n",
        "# cardiometabolic health).\n",
        "\n",
        "WELLCO_RELEVANT_TITLES: set[str] = {\n",
        "    \"Diabetes management\",\n",
        "    \"Hypertension basics\",\n",
        "    \"Stress reduction\",\n",
        "    \"Restorative sleep tips\",\n",
        "    \"Healthy eating guide\",\n",
        "    \"Aerobic exercise\",\n",
        "    \"HbA1c targets\",\n",
        "    \"Strength training basics\",\n",
        "    \"Lowering blood pressure\",\n",
        "    \"Sleep hygiene\",\n",
        "    \"Mediterranean diet\",\n",
        "    \"Cardio workouts\",\n",
        "    \"Exercise routines\",\n",
        "    \"Meditation guide\",\n",
        "    \"Cardiometabolic health\",\n",
        "    \"High-fiber meals\",\n",
        "    \"Cholesterol friendly foods\",\n",
        "    \"Weight management\",\n",
        "}  # 18 titles\n",
        "\n",
        "NOT_RELEVANT_TITLES: set[str] = {\n",
        "    \"Gadget roundup\",\n",
        "    \"Game reviews\",\n",
        "    \"New releases\",\n",
        "    \"Dog training\",\n",
        "    \"Electric vehicles\",\n",
        "    \"Budget planning\",\n",
        "    \"Match highlights\",\n",
        "    \"Top destinations\",\n",
        "}  # 8 titles\n",
        "\n",
        "assert len(WELLCO_RELEVANT_TITLES) + len(NOT_RELEVANT_TITLES) == 26, \\\n",
        "    \"Expected 26 unique titles total\"\n",
        "\n",
        "# ── Build a small fixture DataFrame (new examples to retest the threshold) ───\n",
        "# Different members and a different mix of titles than before, so we can check\n",
        "# that the current SIMILARITY_THRESHOLD generalizes (e.g. 0.2 works on unseen examples).\n",
        "# Ground truth: expected counts come from WELLCO_RELEVANT_TITLES / NOT_RELEVANT_TITLES.\n",
        "\n",
        "_test_rows = [\n",
        "    # Member 10: 2 relevant, 1 not\n",
        "    (10, \"https://x.com/1\", \"Stress reduction\",        \"Mindfulness and wellness\",                    \"2025-08-01 10:00:00\"),\n",
        "    (10, \"https://x.com/2\", \"Healthy eating guide\",    \"Nutrition and balanced diet\",                 \"2025-08-02 11:00:00\"),\n",
        "    (10, \"https://x.com/3\", \"Gadget roundup\",          \"Smartphones and laptops news\",               \"2025-08-03 12:00:00\"),\n",
        "    # Member 11: 3 relevant, 1 not\n",
        "    (11, \"https://y.com/1\", \"Cardio workouts\",         \"Exercise and recovery\",                       \"2025-08-04 09:00:00\"),\n",
        "    (11, \"https://y.com/2\", \"Meditation guide\",        \"Mindfulness and relaxation\",                 \"2025-08-05 10:00:00\"),\n",
        "    (11, \"https://y.com/3\", \"Aerobic exercise\",        \"Cardio and endurance\",                       \"2025-08-06 11:00:00\"),\n",
        "    (11, \"https://y.com/4\", \"New releases\",            \"Box office and trailers\",                    \"2025-08-07 14:00:00\"),\n",
        "    # Member 12: 0 relevant, 2 not\n",
        "    (12, \"https://z.com/1\", \"Match highlights\",        \"League standings and transfers\",             \"2025-08-08 08:00:00\"),\n",
        "    (12, \"https://z.com/2\", \"Top destinations\",       \"City guides and itineraries\",                \"2025-08-09 16:00:00\"),\n",
        "]\n",
        "\n",
        "test_web = pd.DataFrame(_test_rows, columns=[\"member_id\", \"url\", \"title\", \"description\", \"timestamp\"])\n",
        "test_web[\"timestamp\"] = pd.to_datetime(test_web[\"timestamp\"])\n",
        "\n",
        "test_ref = pd.Timestamp(\"2025-08-15\")\n",
        "\n",
        "# ── Run the filter ──────────────────────────────────────────────────────────\n",
        "filtered = filter_wellco_relevant_visits(\n",
        "    test_web,\n",
        "    wellco_embedding=wellco_embedding,\n",
        "    embed_model=embed_model,\n",
        "    similarity_threshold=SIMILARITY_THRESHOLD,\n",
        "    ref_date=test_ref,\n",
        ")\n",
        "\n",
        "counts = filtered.groupby(\"member_id\").size()\n",
        "unique_urls = filtered.groupby(\"member_id\")[\"url\"].nunique()\n",
        "\n",
        "# Expected by ground truth: Member 10 → 2 relevant, 2 unique URLs; 11 → 3, 3; 12 → 0\n",
        "assert counts.get(10, 0) == 2, f\"Member 10: expected 2 relevant visits, got {counts.get(10, 0)}\"\n",
        "assert counts.get(11, 0) == 3, f\"Member 11: expected 3 relevant visits, got {counts.get(11, 0)}\"\n",
        "assert counts.get(12, 0) == 0, f\"Member 12: expected 0 relevant visits, got {counts.get(12, 0)}\"\n",
        "assert unique_urls.get(10, 0) == 2, f\"Member 10: expected 2 unique URLs, got {unique_urls.get(10, 0)}\"\n",
        "assert unique_urls.get(11, 0) == 3, f\"Member 11: expected 3 unique URLs, got {unique_urls.get(11, 0)}\"\n",
        "\n",
        "# Verify no irrelevant titles leaked through\n",
        "assert filtered[\"title\"].isin(NOT_RELEVANT_TITLES).sum() == 0, \\\n",
        "    \"Filter let through visits with non-relevant titles!\"\n",
        "\n",
        "# Verify all retained titles are from the relevant set\n",
        "assert filtered[\"title\"].isin(WELLCO_RELEVANT_TITLES).all(), \\\n",
        "    \"Filter retained titles outside the expected relevant set!\"\n",
        "\n",
        "print(\"✓ All relevance-filter sanity checks passed.\")\n",
        "print(f\"  Member 10: {counts.get(10, 0)} visits, {unique_urls.get(10, 0)} unique URLs\")\n",
        "print(f\"  Member 11: {counts.get(11, 0)} visits, {unique_urls.get(11, 0)} unique URLs\")\n",
        "print(f\"  Member 12: {counts.get(12, 0)} visits (correctly excluded)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fbb875",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## **5. Model Selection — Uplift-Only Cross-Validation**\n",
        "\n",
        "Evaluate 6 candidate uplift models (S-, T-, X-learner × LightGBM, XGBoost) using **stratified K-fold CV** that preserves treatment × churn balance. Models are compared with **uplift-only metrics** (AUUC, Qini, uplift@10 %, uplift@20 %) — no AUC-ROC, accuracy, or other predictive metrics. Segment stability across folds is also reported.\n",
        "\n",
        "**NaN handling:** LightGBM and XGBoost handle NaN natively. CausalML meta-learners pass the feature table through to the base learner. **No imputation** is applied for fit / predict. Imputation is reserved for SHAP only (later section).\n",
        "\n",
        "### **5.1 Configuration**\n",
        "Feature list, cross-validation parameters, and base-learner factories. All hyperparameters are set here for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c301",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.1  Configuration ──────────────────────────────────────────────────────\n",
        "\n",
        "# Feature columns (reused from Section 4.6 — excludes member_id and labels)\n",
        "FEATURE_COLS = [\n",
        "    \"wellco_web_visits_count\",\n",
        "    \"days_since_last_wellco_web\",\n",
        "    \"app_sessions_count\",\n",
        "    \"icd_distinct_count\",\n",
        "    \"has_focus_icd\",\n",
        "    \"days_since_last_claim\",\n",
        "    \"tenure_days\",\n",
        "]\n",
        "\n",
        "# Cross-validation\n",
        "N_SPLITS = 5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Evaluation cut-offs (fraction of population ranked by predicted uplift)\n",
        "TOP_K_LIST = [0.10, 0.20]\n",
        "\n",
        "# Number of points for cumulative uplift curve\n",
        "N_CURVE_POINTS = 100\n",
        "\n",
        "\n",
        "def make_lgbm():\n",
        "    \"\"\"Create a LightGBM regressor configured for shallow, regularised trees.\n",
        "\n",
        "    ``class_weight='balanced'`` up-weights the minority class (churn = 1)\n",
        "    so the base learner is aware of the ~20 % churn imbalance.\n",
        "    \"\"\"\n",
        "    return LGBMRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        num_leaves=31,\n",
        "        min_child_samples=100,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1.0,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbose=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "def make_xgb(scale_pos_weight: float = 1.0):\n",
        "    \"\"\"Create an XGBoost regressor configured for shallow, regularised trees.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    scale_pos_weight : float\n",
        "        Ratio of negative to positive examples — compensates for churn\n",
        "        class imbalance.  Computed from the training fold at runtime.\n",
        "    \"\"\"\n",
        "    return XGBRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=4,\n",
        "        min_child_weight=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1.0,\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=RANDOM_STATE,\n",
        "        verbosity=0,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "\n",
        "# Candidate definitions: (display_name, meta-learner_key, base-learner_key)\n",
        "CANDIDATE_DEFS = [\n",
        "    (\"S + LGBM\", \"S\", \"LGBM\"),\n",
        "    (\"S + XGB\",  \"S\", \"XGB\"),\n",
        "    (\"T + LGBM\", \"T\", \"LGBM\"),\n",
        "    (\"T + XGB\",  \"T\", \"XGB\"),\n",
        "    (\"X + LGBM\", \"X\", \"LGBM\"),\n",
        "    (\"X + XGB\",  \"X\", \"XGB\"),\n",
        "]\n",
        "\n",
        "print(f\"Features ({len(FEATURE_COLS)}): {FEATURE_COLS}\")\n",
        "print(f\"CV: {N_SPLITS}-fold, random_state={RANDOM_STATE}\")\n",
        "print(f\"Candidates: {[c[0] for c in CANDIDATE_DEFS]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c302",
      "metadata": {},
      "source": [
        "### **5.2 Data preparation**\n",
        "Build the modelling arrays from `train_features`. `member_id` is **excluded** (asserted). The combined stratification variable `2 * treatment + churn` creates four cells so that `StratifiedKFold` preserves treatment × churn balance in every fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c303",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.2  Data preparation ───────────────────────────────────────────────────\n",
        "\n",
        "X = train_features[FEATURE_COLS].copy()\n",
        "y = train_features[\"churn\"].astype(int).values\n",
        "treatment = train_features[\"outreach\"].astype(int).values\n",
        "\n",
        "assert \"member_id\" not in X.columns, \"member_id must NOT be a feature!\"\n",
        "assert X.shape[1] == len(FEATURE_COLS)\n",
        "\n",
        "# Combined stratification: 4 groups (control-nochurn, control-churn,\n",
        "#                                     treated-nochurn, treated-churn)\n",
        "stratify_col = 2 * treatment + y\n",
        "\n",
        "# Class-imbalance ratio for XGBoost (negative / positive)\n",
        "_pos = y.sum()\n",
        "_neg = len(y) - _pos\n",
        "SCALE_POS_WEIGHT = _neg / max(_pos, 1)\n",
        "\n",
        "print(f\"X shape:           {X.shape}\")\n",
        "print(f\"Churn rate:        {y.mean():.3f}\")\n",
        "print(f\"Treatment rate:    {treatment.mean():.3f}\")\n",
        "print(f\"scale_pos_weight:  {SCALE_POS_WEIGHT:.2f}\")\n",
        "print(f\"\\nStratify groups:   {dict(zip(*np.unique(stratify_col, return_counts=True)))}\")\n",
        "print(f\"\\nNaN counts:\\n{X.isna().sum().to_string()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c304",
      "metadata": {},
      "source": [
        "**What it means:** The feature matrix has 7 columns and 10,000 rows. Churn rate is ~20 %, treatment rate ~40 %. Two features (`days_since_last_wellco_web`, `days_since_last_claim`) have NaN for members with no activity in that source — these are handled natively by the tree-based base learners.\n",
        "\n",
        "**What it says about further analysis:** The four stratification groups are large enough for 5-fold CV. The class imbalance ratio (~4:1) is passed to XGBoost via `scale_pos_weight` and to LGBM via `class_weight=\"balanced\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c305",
      "metadata": {},
      "source": [
        "### **5.3 Metric helper functions**\n",
        "Custom metric functions used inside the CV loop. All metrics follow the convention **positive uplift = outreach reduces churn** (i.e. `churn_control − churn_treated`).\n",
        "\n",
        "| Function | What it computes |\n",
        "|---|---|\n",
        "| `uplift_at_k` | Realised uplift in the top-*k* fraction ranked by predicted uplift |\n",
        "| `uplift_curve` | Cumulative uplift at evenly spaced fractions of the population |\n",
        "| `approx_auuc` | Area under the uplift curve (trapezoidal rule) |\n",
        "| `assign_segments` | Four uplift segments based on predicted-uplift quartiles |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c306",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.3  Metric helper functions ────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def uplift_at_k(\n",
        "    y_true: np.ndarray,\n",
        "    t_true: np.ndarray,\n",
        "    uplift_scores: np.ndarray,\n",
        "    k: float,\n",
        ") -> float:\n",
        "    \"\"\"Realised uplift in the top-*k* fraction of the population.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array of int\n",
        "        Observed churn labels (0/1).\n",
        "    t_true : array of int\n",
        "        Treatment indicator (1 = outreach, 0 = control).\n",
        "    uplift_scores : array of float\n",
        "        Predicted uplift (higher = more benefit from treatment).\n",
        "    k : float in (0, 1]\n",
        "        Fraction of the population to consider (e.g. 0.10 for top 10 %).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        ``churn_rate_control - churn_rate_treated`` in the top-k segment.\n",
        "        Positive means outreach reduces churn in that segment.\n",
        "    \"\"\"\n",
        "    n = max(1, int(len(uplift_scores) * k))\n",
        "    idx = np.argsort(-uplift_scores)[:n]\n",
        "    y_sub, t_sub = y_true[idx], t_true[idx]\n",
        "    treated = t_sub == 1\n",
        "    control = t_sub == 0\n",
        "    if treated.sum() == 0 or control.sum() == 0:\n",
        "        return np.nan\n",
        "    return float(y_sub[control].mean() - y_sub[treated].mean())\n",
        "\n",
        "\n",
        "def uplift_curve(\n",
        "    y_true: np.ndarray,\n",
        "    t_true: np.ndarray,\n",
        "    uplift_scores: np.ndarray,\n",
        "    n_points: int = 100,\n",
        "):\n",
        "    \"\"\"Cumulative uplift curve evaluated at ``n_points`` fractions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true, t_true, uplift_scores : arrays\n",
        "        Same as ``uplift_at_k``.\n",
        "    n_points : int\n",
        "        Number of evenly spaced evaluation points from 1 % to 100 %.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ks : array of float\n",
        "        Fraction values (0.01 ... 1.0).\n",
        "    uplift_vals : array of float\n",
        "        Realised uplift at each fraction.\n",
        "    \"\"\"\n",
        "    order = np.argsort(-uplift_scores)\n",
        "    y_sorted = y_true[order]\n",
        "    t_sorted = t_true[order]\n",
        "    ks = np.linspace(0.01, 1.0, n_points)\n",
        "    vals = []\n",
        "    for frac in ks:\n",
        "        n = max(1, int(len(y_sorted) * frac))\n",
        "        y_sub, t_sub = y_sorted[:n], t_sorted[:n]\n",
        "        nt, nc = (t_sub == 1).sum(), (t_sub == 0).sum()\n",
        "        if nt == 0 or nc == 0:\n",
        "            vals.append(np.nan)\n",
        "        else:\n",
        "            vals.append(y_sub[t_sub == 0].mean() - y_sub[t_sub == 1].mean())\n",
        "    return ks, np.array(vals)\n",
        "\n",
        "\n",
        "def approx_auuc(ks: np.ndarray, uplift_vals: np.ndarray) -> float:\n",
        "    \"\"\"Area under the uplift curve (trapezoidal rule, NaN-safe).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ks : array of float\n",
        "        Fraction values returned by ``uplift_curve``.\n",
        "    uplift_vals : array of float\n",
        "        Corresponding uplift values.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Approximate AUUC.  Returns ``np.nan`` if all values are NaN.\n",
        "    \"\"\"\n",
        "    valid = ~np.isnan(uplift_vals)\n",
        "    if valid.sum() < 2:\n",
        "        return np.nan\n",
        "    return float(np.trapz(uplift_vals[valid], ks[valid]))\n",
        "\n",
        "\n",
        "def assign_segments(uplift_scores: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Assign four uplift segments based on predicted-uplift quartiles.\n",
        "\n",
        "    Segments\n",
        "    --------\n",
        "    - **Persuadables** (top quartile): highest predicted treatment benefit.\n",
        "    - **Sure Things** (Q50-Q75): moderate predicted benefit.\n",
        "    - **Lost Causes** (Q25-Q50): low predicted benefit.\n",
        "    - **Do-Not-Disturb** (bottom quartile): lowest / negative predicted benefit.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    uplift_scores : array of float\n",
        "        Predicted uplift per member.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    array of str\n",
        "        Segment labels, same length as ``uplift_scores``.\n",
        "    \"\"\"\n",
        "    q25, q50, q75 = np.nanquantile(uplift_scores, [0.25, 0.50, 0.75])\n",
        "    seg = np.empty(len(uplift_scores), dtype=object)\n",
        "    seg[uplift_scores >= q75]                                   = \"Persuadables\"\n",
        "    seg[(uplift_scores >= q50) & (uplift_scores < q75)]         = \"Sure Things\"\n",
        "    seg[(uplift_scores >= q25) & (uplift_scores < q50)]         = \"Lost Causes\"\n",
        "    seg[uplift_scores < q25]                                    = \"Do-Not-Disturb\"\n",
        "    return seg\n",
        "\n",
        "\n",
        "print(\"Metric helpers loaded: uplift_at_k, uplift_curve, approx_auuc, assign_segments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c307",
      "metadata": {},
      "source": [
        "### **5.4 Stratified K-fold cross-validation**\n",
        "For each of the 6 candidate models, run `N_SPLITS`-fold CV. In every fold:\n",
        "\n",
        "1. **Fit** the meta-learner on the training split.\n",
        "2. **Predict uplift** on the validation split.\n",
        "3. **Compute** AUUC, uplift@10 %, uplift@20 %, and assign four segments.\n",
        "4. **Store** per-fold metrics and the cumulative uplift curve for later visualisation.\n",
        "\n",
        "The loop collects everything in `cv_records` (one row per model × fold) and `cv_curves` / `cv_segments` for the diagnostic plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c308",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.4  Stratified K-fold cross-validation ─────────────────────────────────\n",
        "\n",
        "\n",
        "def build_model(meta_key: str, base_key: str, spw: float):\n",
        "    \"\"\"Instantiate a CausalML meta-learner with the requested base learner.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    meta_key : str\n",
        "        One of ``'S'``, ``'T'``, ``'X'``.\n",
        "    base_key : str\n",
        "        One of ``'LGBM'``, ``'XGB'``.\n",
        "    spw : float\n",
        "        ``scale_pos_weight`` for XGBoost (ignored for LGBM).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    CausalML meta-learner instance.\n",
        "    \"\"\"\n",
        "    learner = make_lgbm() if base_key == \"LGBM\" else make_xgb(spw)\n",
        "    meta_map = {\"S\": BaseSRegressor, \"T\": BaseTRegressor, \"X\": BaseXRegressor}\n",
        "    return meta_map[meta_key](learner=learner)\n",
        "\n",
        "\n",
        "# ---- Storage ----------------------------------------------------------------\n",
        "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "cv_records  = []     # one dict per (model, fold)\n",
        "cv_curves   = {}     # model_name -> list of (ks, uplift_vals) per fold\n",
        "cv_segments = {}     # model_name -> list of segment-share Series per fold\n",
        "\n",
        "# ---- Loop -------------------------------------------------------------------\n",
        "for name, meta_key, base_key in CANDIDATE_DEFS:\n",
        "    cv_curves[name]   = []\n",
        "    cv_segments[name] = []\n",
        "\n",
        "    for fold_i, (tr_idx, va_idx) in enumerate(skf.split(X, stratify_col), start=1):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
        "        t_tr, t_va = treatment[tr_idx], treatment[va_idx]\n",
        "\n",
        "        # Fold-specific imbalance ratio\n",
        "        spw = (y_tr == 0).sum() / max((y_tr == 1).sum(), 1)\n",
        "\n",
        "        # Build & fit\n",
        "        model = build_model(meta_key, base_key, spw)\n",
        "        model.fit(X_tr, t_tr, y_tr)\n",
        "\n",
        "        # Predict uplift (positive = outreach reduces churn)\n",
        "        tau = np.asarray(model.predict(X_va)).reshape(-1)\n",
        "\n",
        "        # Metrics\n",
        "        ks, uvals = uplift_curve(y_va, t_va, tau, n_points=N_CURVE_POINTS)\n",
        "        auuc_val  = approx_auuc(ks, uvals)\n",
        "        try:\n",
        "            qini_val = float(qini_auc_score(y_va, tau, t_va)) if qini_auc_score is not None else np.nan\n",
        "        except Exception:\n",
        "            qini_val = np.nan\n",
        "        u10 = uplift_at_k(y_va, t_va, tau, 0.10)\n",
        "        u20 = uplift_at_k(y_va, t_va, tau, 0.20)\n",
        "\n",
        "        # Segment stability\n",
        "        seg       = assign_segments(tau)\n",
        "        seg_share = pd.Series(seg).value_counts(normalize=True)\n",
        "\n",
        "        # Store\n",
        "        cv_records.append({\n",
        "            \"model\": name, \"fold\": fold_i,\n",
        "            \"auuc\": auuc_val, \"qini\": qini_val, \"uplift@10%\": u10, \"uplift@20%\": u20,\n",
        "            \"persuadables_pct\": seg_share.get(\"Persuadables\", 0),\n",
        "            \"sure_things_pct\":  seg_share.get(\"Sure Things\", 0),\n",
        "            \"lost_causes_pct\":  seg_share.get(\"Lost Causes\", 0),\n",
        "            \"dnd_pct\":          seg_share.get(\"Do-Not-Disturb\", 0),\n",
        "        })\n",
        "        cv_curves[name].append((ks, uvals))\n",
        "        cv_segments[name].append(seg_share)\n",
        "\n",
        "        print(f\"[{name}] Fold {fold_i}: AUUC={auuc_val:+.5f}  Qini={qini_val:+.5f}  u@10%={u10:+.4f}  u@20%={u20:+.4f}\")\n",
        "\n",
        "print(f\"\\nCV complete — {len(cv_records)} records \"\n",
        "      f\"({len(CANDIDATE_DEFS)} models x {N_SPLITS} folds).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c309",
      "metadata": {},
      "source": [
        "**What it means:** Each candidate model was trained and evaluated on 5 non-overlapping validation folds. The printed lines show per-fold AUUC and uplift@k so you can spot any fold that behaves very differently from the others (a sign of instability).\n",
        "\n",
        "**What it says about further analysis:** The raw numbers are collected in `cv_records`. The next cells aggregate them into a comparison table and diagnostic plots."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c310",
      "metadata": {},
      "source": [
        "### **5.5 Results summary table**\n",
        "Aggregate per-fold metrics into **mean ± std** per model. The table is sorted by descending mean AUUC. Use this table together with the diagnostic plots below to justify your model choice — balancing **performance** (higher AUUC / uplift@k) with **stability** (lower std across folds) and **segment consistency**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c311",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.5  Results summary table ──────────────────────────────────────────────\n",
        "\n",
        "cv_df = pd.DataFrame(cv_records)\n",
        "\n",
        "summary = (\n",
        "    cv_df\n",
        "    .groupby(\"model\")\n",
        "    .agg(\n",
        "        auuc_mean=(\"auuc\", \"mean\"),\n",
        "        auuc_std=(\"auuc\", \"std\"),\n",
        "        qini_mean=(\"qini\", \"mean\"),\n",
        "        qini_std=(\"qini\", \"std\"),\n",
        "        u10_mean=(\"uplift@10%\", \"mean\"),\n",
        "        u10_std=(\"uplift@10%\", \"std\"),\n",
        "        u20_mean=(\"uplift@20%\", \"mean\"),\n",
        "        u20_std=(\"uplift@20%\", \"std\"),\n",
        "        pers_mean=(\"persuadables_pct\", \"mean\"),\n",
        "        pers_std=(\"persuadables_pct\", \"std\"),\n",
        "    )\n",
        "    .sort_values(\"auuc_mean\", ascending=False)\n",
        ")\n",
        "\n",
        "# Pretty-print\n",
        "print(\"=\" * 90)\n",
        "print(\"  MODEL SELECTION — CV RESULTS  (mean +/- std across folds, sorted by AUUC)\")\n",
        "print(\"=\" * 90)\n",
        "for model, row in summary.iterrows():\n",
        "    print(f\"\\n  {model}\")\n",
        "    print(f\"    AUUC:            {row.auuc_mean:+.5f} +/- {row.auuc_std:.5f}\")\n",
        "    print(f\"    Qini:            {row.qini_mean:+.5f} +/- {row.qini_std:.5f}\")\n",
        "    print(f\"    Uplift @10%:     {row.u10_mean:+.5f} +/- {row.u10_std:.5f}\")\n",
        "    print(f\"    Uplift @20%:     {row.u20_mean:+.5f} +/- {row.u20_std:.5f}\")\n",
        "    print(f\"    Persuadables %:  {row.pers_mean:.3f}  +/- {row.pers_std:.3f}\")\n",
        "\n",
        "display(summary.round(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c312",
      "metadata": {},
      "source": [
        "### **5.6 Diagnostic visualisations**\n",
        "Five charts to support model-selection decisions:\n",
        "\n",
        "| Plot | Purpose |\n",
        "|---|---|\n",
        "| 5.6a AUUC and Qini bar charts | Compare mean AUUC and Qini with error bars (std) across models |\n",
        "| 5.6b Uplift@k grouped bars | Compare uplift@10 % and uplift@20 % side by side |\n",
        "| 5.6c Cumulative uplift curves | Show how uplift accumulates as you target more of the population |\n",
        "| 5.6d Per-fold metric heatmap | Reveal fold-level variation for every model × metric |\n",
        "| 5.6e Segment stability | Check whether Persuadables share is consistent across folds |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c313",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.6a  AUUC and Qini comparison (mean +/- std) ───────────────────────────\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "models = summary.index.tolist()\n",
        "x = np.arange(len(models))\n",
        "pal = sns.color_palette(\"Set2\", len(models))\n",
        "\n",
        "# AUUC\n",
        "ax1.bar(x, summary[\"auuc_mean\"], yerr=summary[\"auuc_std\"], capsize=5,\n",
        "        color=pal, edgecolor=\"black\", alpha=0.85)\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(models, rotation=30, ha=\"right\", fontsize=9)\n",
        "ax1.set_ylabel(\"AUUC (higher = better)\")\n",
        "ax1.set_title(\"AUUC by Model (mean +/- std across CV folds)\", fontsize=11, fontweight=\"bold\")\n",
        "ax1.axhline(0, color=\"grey\", linewidth=0.8, linestyle=\"--\")\n",
        "ax1.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "# Qini\n",
        "ax2.bar(x, summary[\"qini_mean\"], yerr=summary[\"qini_std\"], capsize=5,\n",
        "        color=pal, edgecolor=\"black\", alpha=0.85)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(models, rotation=30, ha=\"right\", fontsize=9)\n",
        "ax2.set_ylabel(\"Qini coefficient (higher = better)\")\n",
        "ax2.set_title(\"Qini by Model (mean +/- std across CV folds)\", fontsize=11, fontweight=\"bold\")\n",
        "ax2.axhline(0, color=\"grey\", linewidth=0.8, linestyle=\"--\")\n",
        "ax2.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c314",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.6b  Uplift@k grouped bar chart ──────────────────────────────────────\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "models = summary.index.tolist()\n",
        "x = np.arange(len(models))\n",
        "w = 0.35\n",
        "ax.bar(x - w / 2, summary[\"u10_mean\"], w, yerr=summary[\"u10_std\"],\n",
        "       capsize=4, label=\"Uplift @10 %\", edgecolor=\"black\", alpha=0.85)\n",
        "ax.bar(x + w / 2, summary[\"u20_mean\"], w, yerr=summary[\"u20_std\"],\n",
        "       capsize=4, label=\"Uplift @20 %\", edgecolor=\"black\", alpha=0.85)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, rotation=30, ha=\"right\", fontsize=9)\n",
        "ax.set_ylabel(\"Churn reduction (control - treated)\")\n",
        "ax.set_title(\"Uplift @k (mean +/- std across CV folds)\",\n",
        "             fontsize=12, fontweight=\"bold\")\n",
        "ax.axhline(0, color=\"grey\", linewidth=0.8, linestyle=\"--\")\n",
        "ax.legend()\n",
        "ax.grid(axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c315",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.6c  Cumulative uplift curves (mean +/- std across folds) ─────────────\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "palette = sns.color_palette(\"tab10\", len(cv_curves))\n",
        "\n",
        "for (name, curve_list), colour in zip(cv_curves.items(), palette):\n",
        "    if not curve_list:\n",
        "        continue\n",
        "    ks = curve_list[0][0]\n",
        "    stack = np.vstack([u for _, u in curve_list])\n",
        "    mean_c = np.nanmean(stack, axis=0)\n",
        "    std_c  = np.nanstd(stack, axis=0)\n",
        "    ax.plot(ks, mean_c, label=name, color=colour, linewidth=2)\n",
        "    ax.fill_between(ks, mean_c - std_c, mean_c + std_c,\n",
        "                    alpha=0.12, color=colour)\n",
        "\n",
        "ax.axhline(0, color=\"grey\", linewidth=0.8, linestyle=\"--\")\n",
        "ax.set_xlabel(\"Fraction of population targeted (ranked by predicted uplift)\")\n",
        "ax.set_ylabel(\"Cumulative uplift (control churn - treated churn)\")\n",
        "ax.set_title(\"Cumulative Uplift Curves — mean +/- 1 std across CV folds\",\n",
        "             fontsize=12, fontweight=\"bold\")\n",
        "ax.legend(loc=\"best\", fontsize=8)\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c316",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.6d  Per-fold metric heatmap ──────────────────────────────────────────\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(24, 5))\n",
        "fig.suptitle(\"Per-Fold Metric Values by Model\",\n",
        "             fontsize=13, fontweight=\"bold\")\n",
        "\n",
        "for ax, metric in zip(axes, [\"auuc\", \"qini\", \"uplift@10%\", \"uplift@20%\"]):\n",
        "    pivot = cv_df.pivot(index=\"model\", columns=\"fold\", values=metric)\n",
        "    sns.heatmap(pivot, annot=True, fmt=\".4f\", cmap=\"RdYlGn\", center=0,\n",
        "                ax=ax, cbar_kws={\"shrink\": 0.8})\n",
        "    ax.set_title(metric.upper(), fontsize=11, fontweight=\"bold\")\n",
        "    ax.set_ylabel(\"\")\n",
        "    ax.set_xlabel(\"Fold\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1b2c317",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── 5.6e  Segment stability (Persuadables share across folds) ──────────────\n",
        "\n",
        "seg_cols = [\"persuadables_pct\", \"sure_things_pct\", \"lost_causes_pct\", \"dnd_pct\"]\n",
        "seg_labels = [\"Persuadables\", \"Sure Things\", \"Lost Causes\", \"Do-Not-Disturb\"]\n",
        "\n",
        "seg_summary = (\n",
        "    cv_df\n",
        "    .groupby(\"model\")[seg_cols]\n",
        "    .agg([\"mean\", \"std\"])\n",
        "    .round(4)\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"  SEGMENT STABILITY (share of validation fold, mean +/- std)\")\n",
        "print(\"=\" * 80)\n",
        "display(seg_summary)\n",
        "\n",
        "# Bar chart: Persuadables share per model\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "models = summary.index.tolist()\n",
        "x = np.arange(len(models))\n",
        "ax.bar(x, summary[\"pers_mean\"], yerr=summary[\"pers_std\"],\n",
        "       capsize=5, color=sns.color_palette(\"Set2\", len(models)),\n",
        "       edgecolor=\"black\", alpha=0.85)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, rotation=30, ha=\"right\", fontsize=9)\n",
        "ax.set_ylabel(\"Persuadables share\")\n",
        "ax.set_title(\"Persuadables Share Stability (mean +/- std across folds)\",\n",
        "             fontsize=12, fontweight=\"bold\")\n",
        "ax.grid(axis=\"y\", alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1b2c318",
      "metadata": {},
      "source": [
        "**What it means:** The five diagnostic plots above show:\n",
        "\n",
        "- **5.6a (AUUC):** Which model has the highest area under the uplift curve, and how much it varies across folds.\n",
        "- **5.6b (Uplift@k):** Whether the model provides real churn reduction when targeting the top 10 % and 20 % of members ranked by predicted uplift.\n",
        "- **5.6c (Cumulative curves):** How uplift accumulates as you contact a larger share of the population — look for curves that stay above zero and separate clearly from others.\n",
        "- **5.6d (Heatmap):** Fold-by-fold stability — a model with one very high fold and four near-zero folds is unreliable.\n",
        "- **5.6e (Segments):** Whether the Persuadables share is roughly constant across folds (~25 % by construction of quartiles, but actual treated-vs-control uplift inside that segment can vary).\n",
        "\n",
        "**What it says about further analysis:** Choose the model that balances the highest mean AUUC / uplift@k with the lowest cross-fold variance and stable segment sizes. That model will be retrained on the full training set in Section 6 (final training), then scored on the test set."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
